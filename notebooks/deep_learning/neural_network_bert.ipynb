{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../libs')\n",
    "from utils import get_data, temporal_train_test_split, evaluate_keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(\"../../data/authors_bert.csv\", select_authors=False).drop([\"Unnamed: 0\", \"comment\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, output_shape):  \n",
    "    model = keras.models.Sequential(name=\"NeuralNetwork\")\n",
    "    model.add(keras.layers.Input(shape=input_shape, name=\"Input\"))\n",
    "    model.add(keras.layers.Dense(30, activation=\"relu\", name=\"Dense1\"))\n",
    "    model.add(keras.layers.Dense(30, activation=\"relu\", name=\"Dense2\"))\n",
    "    model.add(keras.layers.Dense(30, activation=\"relu\", name=\"Dense3\"))\n",
    "    model.add(keras.layers.Dense(output_shape, activation=\"softmax\", name=\"Output\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 21:05:48.377188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-04 21:05:48.410354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-04 21:05:48.410369: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-04 21:05:48.410811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 952us/step\n",
      "15/15 [==============================] - 0s 892us/step\n",
      "15/15 [==============================] - 0s 825us/step\n",
      "15/15 [==============================] - 0s 961us/step\n",
      "13/13 [==============================] - 0s 898us/step\n",
      "15/15 [==============================] - 0s 894us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 877us/step\n",
      "15/15 [==============================] - 0s 861us/step\n",
      "15/15 [==============================] - 0s 974us/step\n",
      "15/15 [==============================] - 0s 889us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 911us/step\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "15/15 [==============================] - 0s 977us/step\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 987us/step\n",
      "15/15 [==============================] - 0s 917us/step\n",
      "14/14 [==============================] - 0s 908us/step\n",
      "15/15 [==============================] - 0s 941us/step\n",
      "14/14 [==============================] - 0s 913us/step\n",
      "14/14 [==============================] - 0s 893us/step\n",
      "14/14 [==============================] - 0s 986us/step\n",
      "14/14 [==============================] - 0s 900us/step\n",
      "15/15 [==============================] - 0s 986us/step\n",
      "13/13 [==============================] - 0s 972us/step\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 935us/step\n",
      "14/14 [==============================] - 0s 898us/step\n",
      "15/15 [==============================] - 0s 903us/step\n",
      "15/15 [==============================] - 0s 962us/step\n",
      "14/14 [==============================] - 0s 893us/step\n",
      "15/15 [==============================] - 0s 893us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 957us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 968us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 996us/step\n",
      "15/15 [==============================] - 0s 960us/step\n",
      "15/15 [==============================] - 0s 945us/step\n",
      "15/15 [==============================] - 0s 927us/step\n",
      "15/15 [==============================] - 0s 919us/step\n",
      "15/15 [==============================] - 0s 893us/step\n",
      "15/15 [==============================] - 0s 948us/step\n",
      "15/15 [==============================] - 0s 963us/step\n",
      "14/14 [==============================] - 0s 963us/step\n",
      "15/15 [==============================] - 0s 946us/step\n",
      "13/13 [==============================] - 0s 965us/step\n",
      "15/15 [==============================] - 0s 921us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 910us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 955us/step\n",
      "15/15 [==============================] - 0s 895us/step\n",
      "15/15 [==============================] - 0s 927us/step\n",
      "15/15 [==============================] - 0s 961us/step\n",
      "16/16 [==============================] - 0s 908us/step\n",
      "14/14 [==============================] - 0s 915us/step\n",
      "15/15 [==============================] - 0s 924us/step\n",
      "15/15 [==============================] - 0s 959us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 987us/step\n",
      "15/15 [==============================] - 0s 924us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 881us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 903us/step\n",
      "15/15 [==============================] - 0s 914us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 909us/step\n",
      "15/15 [==============================] - 0s 898us/step\n",
      "14/14 [==============================] - 0s 902us/step\n",
      "15/15 [==============================] - 0s 929us/step\n",
      "13/13 [==============================] - 0s 957us/step\n",
      "15/15 [==============================] - 0s 880us/step\n",
      "15/15 [==============================] - 0s 947us/step\n",
      "15/15 [==============================] - 0s 887us/step\n",
      "15/15 [==============================] - 0s 929us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 934us/step\n",
      "14/14 [==============================] - 0s 924us/step\n",
      "15/15 [==============================] - 0s 894us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 950us/step\n",
      "15/15 [==============================] - 0s 975us/step\n",
      "15/15 [==============================] - 0s 918us/step\n",
      "13/13 [==============================] - 0s 974us/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 955us/step\n",
      "13/13 [==============================] - 0s 924us/step\n",
      "14/14 [==============================] - 0s 957us/step\n",
      "15/15 [==============================] - 0s 878us/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 925us/step\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "15/15 [==============================] - 0s 955us/step\n"
     ]
    }
   ],
   "source": [
    "usernames = list(np.unique(data[\"username\"]))\n",
    "results = list()\n",
    "metrics = list()\n",
    "evaluation = list()\n",
    "\n",
    "for i in range(len(usernames)):\n",
    "    author1 = usernames.pop()\n",
    "\n",
    "    for author2 in usernames:\n",
    "        X_train, X_test, y_train, y_test = temporal_train_test_split(\n",
    "            data, author1, author2)\n",
    "\n",
    "        y_classes = pd.get_dummies(y_train).columns\n",
    "        y_train = pd.get_dummies(y_train).values\n",
    "        y_test = pd.get_dummies(y_test).values\n",
    "        \n",
    "        input_shape_text = X_train.shape[1]\n",
    "        output_shape = y_train.shape[1]\n",
    "\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "        model = build_model(input_shape_text, output_shape)\n",
    "        model.compile(loss = \"categorical_crossentropy\",\n",
    "                    optimizer = keras.optimizers.SGD(learning_rate=0.01),\n",
    "                    metrics = [\"accuracy\"])\n",
    "        history = model.fit(X_train, y_train, epochs=1000, callbacks=[callback], validation_split=0.1, shuffle=True, verbose=False)\n",
    "\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        evaluation.append(evaluate_keras(y_test.argmax(1), y_pred_proba, *y_classes))\n",
    "        metrics = pd.DataFrame(evaluation)[[\"f1_macro\", \"recall_macro\", \"precision_macro\", \"accuracy\", \"auc_score\"]].mean()\n",
    "results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87017</td>\n",
       "      <td>0.870333</td>\n",
       "      <td>0.871621</td>\n",
       "      <td>0.870609</td>\n",
       "      <td>0.936238</td>\n",
       "      <td>Neural Network with BERT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_macro  recall_macro  precision_macro  accuracy  auc_score  \\\n",
       "0   0.87017      0.870333         0.871621  0.870609   0.936238   \n",
       "\n",
       "                        clf  \n",
       "0  Neural Network with BERT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([results[i] for i in range(len(results))])\n",
    "metrics_df[\"clf\"] = \"Neural Network with BERT\"\n",
    "metrics_df.to_csv(\"../../results/neural_network_bert.csv\")\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c47aa80a392bf6b860d7beb7b265756c1d97ffcd6d5effdf04ac88dd49d67208"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('reddit-in-portuguese-CNZVnMpw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

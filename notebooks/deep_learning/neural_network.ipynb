{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 01:40:05.782460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-04 01:40:05.782485: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../libs')\n",
    "from utils import get_data, temporal_train_test_split, evaluate_keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(\"../../data/authors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TweetTokenizer()\n",
    "\n",
    "vectorizers = [CountVectorizer(ngram_range=(1,1), analyzer=\"word\", tokenizer=tt.tokenize, max_features=10000), \n",
    "                CountVectorizer(ngram_range=(1,3), analyzer=\"word\", tokenizer=tt.tokenize, max_features=10000), \n",
    "                CountVectorizer(ngram_range=(1,5), analyzer=\"char\", max_features=10000), \n",
    "                CountVectorizer(ngram_range=(4,5), analyzer=\"char\", max_features=10000), \n",
    "                CountVectorizer(ngram_range=(3,8), analyzer=\"char\", max_features=10000), \n",
    "                TfidfVectorizer(ngram_range=(1,1), analyzer=\"word\", tokenizer=tt.tokenize, max_features=10000),  \n",
    "                TfidfVectorizer(ngram_range=(1,3), analyzer=\"word\", tokenizer=tt.tokenize, max_features=10000), \n",
    "                TfidfVectorizer(ngram_range=(1,5), analyzer=\"char\", max_features=10000), \n",
    "                TfidfVectorizer(ngram_range=(4,5), analyzer=\"char\", max_features=10000), \n",
    "                TfidfVectorizer(ngram_range=(3,8), analyzer=\"char\", max_features=10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, output_shape):  \n",
    "    model = keras.models.Sequential(name=\"NeuralNetwork\")\n",
    "    model.add(keras.layers.Input(shape=input_shape, name=\"Input\"))\n",
    "    model.add(keras.layers.Dense(30, activation=\"relu\", name=\"Dense1\"))\n",
    "    model.add(keras.layers.Dense(30, activation=\"relu\", name=\"Dense2\"))\n",
    "    model.add(keras.layers.Dense(30, activation=\"relu\", name=\"Dense3\"))\n",
    "    model.add(keras.layers.Dense(output_shape, activation=\"softmax\", name=\"Output\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running => CountVectorizer(max_features=10000,\n",
      "                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f688e5ba850>>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 01:40:09.028691: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-04 01:40:09.028725: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-04 01:40:09.028751: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lenovo-214): /proc/driver/nvidia/version does not exist\n",
      "2022-06-04 01:40:09.029019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.6933 - accuracy: 0.4890 - val_loss: 0.6923 - val_accuracy: 0.5306\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.5246 - val_loss: 0.6919 - val_accuracy: 0.5578\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.5465 - val_loss: 0.6912 - val_accuracy: 0.5306\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5495 - val_loss: 0.6906 - val_accuracy: 0.5442\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.5261 - val_loss: 0.6901 - val_accuracy: 0.5918\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.6228 - val_loss: 0.6889 - val_accuracy: 0.5782\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6866 - accuracy: 0.5865 - val_loss: 0.6876 - val_accuracy: 0.6531\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.6712 - val_loss: 0.6853 - val_accuracy: 0.5986\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.6772 - val_loss: 0.6826 - val_accuracy: 0.6735\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.7317 - val_loss: 0.6788 - val_accuracy: 0.6531\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6725 - accuracy: 0.7324 - val_loss: 0.6744 - val_accuracy: 0.7279\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6661 - accuracy: 0.7853 - val_loss: 0.6686 - val_accuracy: 0.7415\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6584 - accuracy: 0.8057 - val_loss: 0.6620 - val_accuracy: 0.7415\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6491 - accuracy: 0.8171 - val_loss: 0.6532 - val_accuracy: 0.7551\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6379 - accuracy: 0.8413 - val_loss: 0.6433 - val_accuracy: 0.7755\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6252 - accuracy: 0.8443 - val_loss: 0.6318 - val_accuracy: 0.7619\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6107 - accuracy: 0.8685 - val_loss: 0.6188 - val_accuracy: 0.7891\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5937 - accuracy: 0.8760 - val_loss: 0.6036 - val_accuracy: 0.8027\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5743 - accuracy: 0.8791 - val_loss: 0.5865 - val_accuracy: 0.8027\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.5526 - accuracy: 0.8912 - val_loss: 0.5675 - val_accuracy: 0.8299\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5281 - accuracy: 0.8987 - val_loss: 0.5474 - val_accuracy: 0.8639\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.9055 - val_loss: 0.5247 - val_accuracy: 0.8435\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.9131 - val_loss: 0.5014 - val_accuracy: 0.8639\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.9229 - val_loss: 0.4772 - val_accuracy: 0.8503\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.9289 - val_loss: 0.4537 - val_accuracy: 0.8776\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.9418 - val_loss: 0.4292 - val_accuracy: 0.8776\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.9448 - val_loss: 0.4063 - val_accuracy: 0.8844\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.3133 - accuracy: 0.9509 - val_loss: 0.3849 - val_accuracy: 0.8912\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2833 - accuracy: 0.9569 - val_loss: 0.3646 - val_accuracy: 0.8912\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2558 - accuracy: 0.9607 - val_loss: 0.3490 - val_accuracy: 0.8912\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9735 - val_loss: 0.3308 - val_accuracy: 0.9048\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2073 - accuracy: 0.9735 - val_loss: 0.3166 - val_accuracy: 0.9116\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1868 - accuracy: 0.9788 - val_loss: 0.3033 - val_accuracy: 0.9116\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1683 - accuracy: 0.9826 - val_loss: 0.2921 - val_accuracy: 0.9184\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1519 - accuracy: 0.9849 - val_loss: 0.2822 - val_accuracy: 0.9184\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1373 - accuracy: 0.9902 - val_loss: 0.2740 - val_accuracy: 0.9184\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1246 - accuracy: 0.9894 - val_loss: 0.2638 - val_accuracy: 0.9184\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9872 - val_loss: 0.2578 - val_accuracy: 0.9252\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.9894 - val_loss: 0.2497 - val_accuracy: 0.9252\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0942 - accuracy: 0.9917 - val_loss: 0.2443 - val_accuracy: 0.9388\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9947 - val_loss: 0.2387 - val_accuracy: 0.9320\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9932 - val_loss: 0.2390 - val_accuracy: 0.9388\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9962 - val_loss: 0.2312 - val_accuracy: 0.9456\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9970 - val_loss: 0.2262 - val_accuracy: 0.9388\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9985 - val_loss: 0.2242 - val_accuracy: 0.9388\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0566 - accuracy: 0.9977 - val_loss: 0.2198 - val_accuracy: 0.9388\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9388\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9388\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9320\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9388\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9388\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9388\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9388\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9388\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9388\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9388\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9388\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9388\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9388\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9320\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9388\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9388\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9388\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9388\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9320\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9388\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9388\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9388\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9388\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9388\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9388\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9388\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9388\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9388\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9388\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9388\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9388\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9388\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9388\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9388\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9388\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9388\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9388\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9388\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9320\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9388\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9320\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9320\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9320\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9388\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9388\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9388\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9388\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9388\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9388\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9388\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9388\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9320\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9388\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9320\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9320\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9388\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9320\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9320\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9320\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9388\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "==================\n",
      "F1: 0.8758\n",
      "Acc: 0.876\n",
      "AUC: 0.9286\n",
      "==================\n",
      "Running => CountVectorizer(max_features=10000, ngram_range=(1, 3),\n",
      "                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f688e5ba850>>)\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 11ms/step - loss: 0.6938 - accuracy: 0.5004 - val_loss: 0.6940 - val_accuracy: 0.4899\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6925 - accuracy: 0.5116 - val_loss: 0.6938 - val_accuracy: 0.5034\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5332 - val_loss: 0.6936 - val_accuracy: 0.5302\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6902 - accuracy: 0.5481 - val_loss: 0.6934 - val_accuracy: 0.5369\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5682 - val_loss: 0.6931 - val_accuracy: 0.5369\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.5884 - val_loss: 0.6927 - val_accuracy: 0.5369\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6864 - accuracy: 0.6092 - val_loss: 0.6923 - val_accuracy: 0.5570\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6849 - accuracy: 0.6301 - val_loss: 0.6918 - val_accuracy: 0.5705\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6831 - accuracy: 0.6637 - val_loss: 0.6911 - val_accuracy: 0.5705\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6812 - accuracy: 0.6592 - val_loss: 0.6905 - val_accuracy: 0.5772\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.6943 - val_loss: 0.6895 - val_accuracy: 0.5570\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.7017 - val_loss: 0.6884 - val_accuracy: 0.5570\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.7263 - val_loss: 0.6868 - val_accuracy: 0.5772\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.7286 - val_loss: 0.6849 - val_accuracy: 0.5906\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.7539 - val_loss: 0.6824 - val_accuracy: 0.6040\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.7666 - val_loss: 0.6794 - val_accuracy: 0.6107\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6529 - accuracy: 0.8001 - val_loss: 0.6755 - val_accuracy: 0.6242\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6448 - accuracy: 0.8203 - val_loss: 0.6709 - val_accuracy: 0.6577\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6352 - accuracy: 0.8374 - val_loss: 0.6651 - val_accuracy: 0.6577\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6240 - accuracy: 0.8509 - val_loss: 0.6582 - val_accuracy: 0.6711\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6108 - accuracy: 0.8740 - val_loss: 0.6497 - val_accuracy: 0.7315\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5953 - accuracy: 0.8814 - val_loss: 0.6400 - val_accuracy: 0.7315\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5778 - accuracy: 0.9008 - val_loss: 0.6284 - val_accuracy: 0.7450\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.9083 - val_loss: 0.6151 - val_accuracy: 0.7651\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.9165 - val_loss: 0.6003 - val_accuracy: 0.7785\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.9210 - val_loss: 0.5839 - val_accuracy: 0.8054\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.9336 - val_loss: 0.5667 - val_accuracy: 0.8121\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.9418 - val_loss: 0.5491 - val_accuracy: 0.8054\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.9523 - val_loss: 0.5308 - val_accuracy: 0.8188\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.9553 - val_loss: 0.5120 - val_accuracy: 0.8188\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.9597 - val_loss: 0.4946 - val_accuracy: 0.8188\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.9642 - val_loss: 0.4733 - val_accuracy: 0.8121\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.3123 - accuracy: 0.9724 - val_loss: 0.4565 - val_accuracy: 0.8188\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2859 - accuracy: 0.9724 - val_loss: 0.4421 - val_accuracy: 0.8322\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2612 - accuracy: 0.9791 - val_loss: 0.4254 - val_accuracy: 0.8188\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2380 - accuracy: 0.9806 - val_loss: 0.4129 - val_accuracy: 0.8322\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.2170 - accuracy: 0.9784 - val_loss: 0.3961 - val_accuracy: 0.8389\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1977 - accuracy: 0.9858 - val_loss: 0.3882 - val_accuracy: 0.8389\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1803 - accuracy: 0.9851 - val_loss: 0.3792 - val_accuracy: 0.8322\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.9858 - val_loss: 0.3706 - val_accuracy: 0.8389\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1505 - accuracy: 0.9866 - val_loss: 0.3642 - val_accuracy: 0.8456\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1373 - accuracy: 0.9896 - val_loss: 0.3592 - val_accuracy: 0.8456\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1264 - accuracy: 0.9896 - val_loss: 0.3478 - val_accuracy: 0.8591\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.9896 - val_loss: 0.3443 - val_accuracy: 0.8591\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1073 - accuracy: 0.9896 - val_loss: 0.3432 - val_accuracy: 0.8456\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0994 - accuracy: 0.9911 - val_loss: 0.3390 - val_accuracy: 0.8523\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0925 - accuracy: 0.9918 - val_loss: 0.3404 - val_accuracy: 0.8523\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9896 - val_loss: 0.3333 - val_accuracy: 0.8523\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0798 - accuracy: 0.9911 - val_loss: 0.3298 - val_accuracy: 0.8322\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 0.9918 - val_loss: 0.3305 - val_accuracy: 0.8456\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.9911 - val_loss: 0.3288 - val_accuracy: 0.8255\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9933 - val_loss: 0.3395 - val_accuracy: 0.8523\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9925 - val_loss: 0.3311 - val_accuracy: 0.8523\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0588 - accuracy: 0.9911 - val_loss: 0.3382 - val_accuracy: 0.8523\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0558 - accuracy: 0.9918 - val_loss: 0.3311 - val_accuracy: 0.8456\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9933 - val_loss: 0.3315 - val_accuracy: 0.8389\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0502 - accuracy: 0.9925 - val_loss: 0.3361 - val_accuracy: 0.8591\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9940 - val_loss: 0.3387 - val_accuracy: 0.8658\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9940 - val_loss: 0.3407 - val_accuracy: 0.8591\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0435 - accuracy: 0.9948 - val_loss: 0.3375 - val_accuracy: 0.8523\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9955 - val_loss: 0.3462 - val_accuracy: 0.8591\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9955 - val_loss: 0.3412 - val_accuracy: 0.8456\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 0.9955 - val_loss: 0.3463 - val_accuracy: 0.8591\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9955 - val_loss: 0.3468 - val_accuracy: 0.8591\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9940 - val_loss: 0.3511 - val_accuracy: 0.8591\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9948 - val_loss: 0.3536 - val_accuracy: 0.8523\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9955 - val_loss: 0.3582 - val_accuracy: 0.8591\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9955 - val_loss: 0.3524 - val_accuracy: 0.8523\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9955 - val_loss: 0.3502 - val_accuracy: 0.8456\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9955 - val_loss: 0.3581 - val_accuracy: 0.8591\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9955 - val_loss: 0.3559 - val_accuracy: 0.8456\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9955 - val_loss: 0.3583 - val_accuracy: 0.8456\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9955 - val_loss: 0.3593 - val_accuracy: 0.8456\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9955 - val_loss: 0.3606 - val_accuracy: 0.8456\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9955 - val_loss: 0.3736 - val_accuracy: 0.8591\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9955 - val_loss: 0.3702 - val_accuracy: 0.8591\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9955 - val_loss: 0.3664 - val_accuracy: 0.8456\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9955 - val_loss: 0.3681 - val_accuracy: 0.8456\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9955 - val_loss: 0.3660 - val_accuracy: 0.8389\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9955 - val_loss: 0.3719 - val_accuracy: 0.8456\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9955 - val_loss: 0.3726 - val_accuracy: 0.8456\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "==================\n",
      "F1: 0.8513999999999999\n",
      "Acc: 0.85165\n",
      "AUC: 0.9160999999999999\n",
      "==================\n",
      "Running => CountVectorizer(analyzer='char', max_features=10000, ngram_range=(1, 5))\n",
      "Epoch 1/1000\n",
      "40/40 [==============================] - 1s 11ms/step - loss: 0.6939 - accuracy: 0.4787 - val_loss: 0.6953 - val_accuracy: 0.4648\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6876 - accuracy: 0.5465 - val_loss: 0.6901 - val_accuracy: 0.5282\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.5913 - val_loss: 0.6843 - val_accuracy: 0.6197\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6717 - accuracy: 0.6906 - val_loss: 0.6763 - val_accuracy: 0.6831\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 0.7181 - val_loss: 0.6667 - val_accuracy: 0.6972\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6465 - accuracy: 0.7504 - val_loss: 0.6544 - val_accuracy: 0.7254\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6288 - accuracy: 0.7646 - val_loss: 0.6389 - val_accuracy: 0.7817\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.7874 - val_loss: 0.6193 - val_accuracy: 0.8028\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5793 - accuracy: 0.8094 - val_loss: 0.5972 - val_accuracy: 0.8099\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5457 - accuracy: 0.8323 - val_loss: 0.5744 - val_accuracy: 0.8028\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5061 - accuracy: 0.8591 - val_loss: 0.5442 - val_accuracy: 0.8380\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.8858 - val_loss: 0.5147 - val_accuracy: 0.8380\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.8953 - val_loss: 0.4843 - val_accuracy: 0.8451\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.9110 - val_loss: 0.4557 - val_accuracy: 0.8521\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.9260 - val_loss: 0.4346 - val_accuracy: 0.8451\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.2961 - accuracy: 0.9339 - val_loss: 0.4029 - val_accuracy: 0.8803\n",
      "Epoch 17/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.2631 - accuracy: 0.9457 - val_loss: 0.3841 - val_accuracy: 0.8873\n",
      "Epoch 18/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.2330 - accuracy: 0.9496 - val_loss: 0.3715 - val_accuracy: 0.8592\n",
      "Epoch 19/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.2072 - accuracy: 0.9567 - val_loss: 0.3541 - val_accuracy: 0.8803\n",
      "Epoch 20/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1848 - accuracy: 0.9638 - val_loss: 0.3448 - val_accuracy: 0.8732\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.9693 - val_loss: 0.3367 - val_accuracy: 0.8732\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.9756 - val_loss: 0.3291 - val_accuracy: 0.8803\n",
      "Epoch 23/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1327 - accuracy: 0.9772 - val_loss: 0.3267 - val_accuracy: 0.8732\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9780 - val_loss: 0.3214 - val_accuracy: 0.8873\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.1081 - accuracy: 0.9803 - val_loss: 0.3185 - val_accuracy: 0.8873\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0980 - accuracy: 0.9835 - val_loss: 0.3178 - val_accuracy: 0.8873\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.9850 - val_loss: 0.3159 - val_accuracy: 0.9014\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9874 - val_loss: 0.3159 - val_accuracy: 0.8944\n",
      "Epoch 29/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9898 - val_loss: 0.3176 - val_accuracy: 0.8944\n",
      "Epoch 30/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 0.9906 - val_loss: 0.3185 - val_accuracy: 0.8944\n",
      "Epoch 31/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9921 - val_loss: 0.3175 - val_accuracy: 0.9014\n",
      "Epoch 32/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9937 - val_loss: 0.3191 - val_accuracy: 0.9014\n",
      "Epoch 33/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9945 - val_loss: 0.3221 - val_accuracy: 0.8944\n",
      "Epoch 34/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9945 - val_loss: 0.3243 - val_accuracy: 0.8873\n",
      "Epoch 35/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0472 - accuracy: 0.9945 - val_loss: 0.3260 - val_accuracy: 0.8944\n",
      "Epoch 36/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0441 - accuracy: 0.9945 - val_loss: 0.3290 - val_accuracy: 0.8873\n",
      "Epoch 37/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 0.9961 - val_loss: 0.3305 - val_accuracy: 0.8944\n",
      "Epoch 38/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9961 - val_loss: 0.3330 - val_accuracy: 0.8944\n",
      "Epoch 39/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9961 - val_loss: 0.3365 - val_accuracy: 0.8873\n",
      "Epoch 40/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9969 - val_loss: 0.3381 - val_accuracy: 0.9014\n",
      "Epoch 41/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9961 - val_loss: 0.3403 - val_accuracy: 0.9014\n",
      "Epoch 42/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 0.9961 - val_loss: 0.3436 - val_accuracy: 0.8873\n",
      "Epoch 43/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9961 - val_loss: 0.3450 - val_accuracy: 0.9014\n",
      "Epoch 44/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9969 - val_loss: 0.3474 - val_accuracy: 0.9014\n",
      "Epoch 45/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9969 - val_loss: 0.3500 - val_accuracy: 0.9014\n",
      "Epoch 46/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9969 - val_loss: 0.3524 - val_accuracy: 0.9014\n",
      "Epoch 47/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.3549 - val_accuracy: 0.8944\n",
      "Epoch 48/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9969 - val_loss: 0.3580 - val_accuracy: 0.8944\n",
      "Epoch 49/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 0.9969 - val_loss: 0.3598 - val_accuracy: 0.9014\n",
      "Epoch 50/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.3622 - val_accuracy: 0.9014\n",
      "Epoch 51/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.3649 - val_accuracy: 0.8944\n",
      "Epoch 52/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.3667 - val_accuracy: 0.8944\n",
      "Epoch 53/1000\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.3689 - val_accuracy: 0.8944\n",
      "Epoch 54/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.3711 - val_accuracy: 0.8944\n",
      "Epoch 55/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.3734 - val_accuracy: 0.8944\n",
      "Epoch 56/1000\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9976 - val_loss: 0.3753 - val_accuracy: 0.8944\n",
      "Epoch 57/1000\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 0.9976 - val_loss: 0.3773 - val_accuracy: 0.8873\n",
      "Epoch 58/1000\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9976 - val_loss: 0.3796 - val_accuracy: 0.8944\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "==================\n",
      "F1: 0.8416\n",
      "Acc: 0.8417666666666667\n",
      "AUC: 0.9115666666666665\n",
      "==================\n",
      "Running => CountVectorizer(analyzer='char', max_features=10000, ngram_range=(4, 5))\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.6991 - accuracy: 0.4601 - val_loss: 0.6965 - val_accuracy: 0.4898\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6918 - accuracy: 0.4928 - val_loss: 0.6917 - val_accuracy: 0.4898\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6848 - accuracy: 0.5626 - val_loss: 0.6875 - val_accuracy: 0.5442\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6771 - accuracy: 0.6249 - val_loss: 0.6819 - val_accuracy: 0.6259\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6671 - accuracy: 0.7024 - val_loss: 0.6740 - val_accuracy: 0.6190\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6546 - accuracy: 0.7578 - val_loss: 0.6652 - val_accuracy: 0.6803\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6392 - accuracy: 0.8056 - val_loss: 0.6535 - val_accuracy: 0.6871\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6202 - accuracy: 0.8147 - val_loss: 0.6410 - val_accuracy: 0.6939\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5989 - accuracy: 0.8345 - val_loss: 0.6268 - val_accuracy: 0.6871\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5747 - accuracy: 0.8360 - val_loss: 0.6100 - val_accuracy: 0.6871\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5481 - accuracy: 0.8542 - val_loss: 0.5941 - val_accuracy: 0.7007\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5188 - accuracy: 0.8656 - val_loss: 0.5817 - val_accuracy: 0.7007\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.8610 - val_loss: 0.5611 - val_accuracy: 0.6939\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.8778 - val_loss: 0.5444 - val_accuracy: 0.7007\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8990 - val_loss: 0.5277 - val_accuracy: 0.7415\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.9074 - val_loss: 0.5138 - val_accuracy: 0.7415\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3516 - accuracy: 0.9127 - val_loss: 0.4979 - val_accuracy: 0.7415\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.3198 - accuracy: 0.9256 - val_loss: 0.4826 - val_accuracy: 0.7483\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2916 - accuracy: 0.9362 - val_loss: 0.4725 - val_accuracy: 0.7619\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2640 - accuracy: 0.9431 - val_loss: 0.4652 - val_accuracy: 0.7619\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2392 - accuracy: 0.9476 - val_loss: 0.4595 - val_accuracy: 0.7619\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2173 - accuracy: 0.9506 - val_loss: 0.4520 - val_accuracy: 0.7823\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9598 - val_loss: 0.4522 - val_accuracy: 0.7823\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1791 - accuracy: 0.9620 - val_loss: 0.4457 - val_accuracy: 0.7891\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1627 - accuracy: 0.9651 - val_loss: 0.4421 - val_accuracy: 0.7891\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.9689 - val_loss: 0.4414 - val_accuracy: 0.7891\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1350 - accuracy: 0.9719 - val_loss: 0.4397 - val_accuracy: 0.8027\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1232 - accuracy: 0.9749 - val_loss: 0.4384 - val_accuracy: 0.8027\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1129 - accuracy: 0.9803 - val_loss: 0.4391 - val_accuracy: 0.7959\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1035 - accuracy: 0.9818 - val_loss: 0.4423 - val_accuracy: 0.7959\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.0955 - accuracy: 0.9810 - val_loss: 0.4444 - val_accuracy: 0.7959\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0882 - accuracy: 0.9810 - val_loss: 0.4456 - val_accuracy: 0.8095\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9825 - val_loss: 0.4484 - val_accuracy: 0.8095\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9833 - val_loss: 0.4512 - val_accuracy: 0.8027\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.9856 - val_loss: 0.4551 - val_accuracy: 0.8027\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9848 - val_loss: 0.4621 - val_accuracy: 0.8027\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9879 - val_loss: 0.4641 - val_accuracy: 0.8095\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9879 - val_loss: 0.4690 - val_accuracy: 0.8027\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9916 - val_loss: 0.4741 - val_accuracy: 0.7959\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.9901 - val_loss: 0.4806 - val_accuracy: 0.7959\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0472 - accuracy: 0.9901 - val_loss: 0.4818 - val_accuracy: 0.8027\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9932 - val_loss: 0.4878 - val_accuracy: 0.8027\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9932 - val_loss: 0.4932 - val_accuracy: 0.7959\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9947 - val_loss: 0.4964 - val_accuracy: 0.7959\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9939 - val_loss: 0.5011 - val_accuracy: 0.8027\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9939 - val_loss: 0.5049 - val_accuracy: 0.8027\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9947 - val_loss: 0.5099 - val_accuracy: 0.8027\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9947 - val_loss: 0.5149 - val_accuracy: 0.8027\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9947 - val_loss: 0.5217 - val_accuracy: 0.7959\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9947 - val_loss: 0.5231 - val_accuracy: 0.8027\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9954 - val_loss: 0.5261 - val_accuracy: 0.8027\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9954 - val_loss: 0.5308 - val_accuracy: 0.8027\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9962 - val_loss: 0.5337 - val_accuracy: 0.8027\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.5385 - val_accuracy: 0.8027\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9962 - val_loss: 0.5437 - val_accuracy: 0.7959\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9962 - val_loss: 0.5437 - val_accuracy: 0.8027\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9962 - val_loss: 0.5495 - val_accuracy: 0.7959\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9970 - val_loss: 0.5543 - val_accuracy: 0.7959\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "==================\n",
      "F1: 0.830075\n",
      "Acc: 0.8302\n",
      "AUC: 0.9044249999999999\n",
      "==================\n",
      "Running => CountVectorizer(analyzer='char', max_features=10000, ngram_range=(3, 8))\n",
      "Epoch 1/1000\n",
      "41/41 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.4656 - val_loss: 0.6928 - val_accuracy: 0.4444\n",
      "Epoch 2/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6870 - accuracy: 0.5174 - val_loss: 0.6876 - val_accuracy: 0.5069\n",
      "Epoch 3/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6810 - accuracy: 0.5598 - val_loss: 0.6822 - val_accuracy: 0.5208\n",
      "Epoch 4/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.6193 - val_loss: 0.6754 - val_accuracy: 0.5486\n",
      "Epoch 5/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6637 - accuracy: 0.6649 - val_loss: 0.6674 - val_accuracy: 0.6319\n",
      "Epoch 6/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.6519 - accuracy: 0.7305 - val_loss: 0.6573 - val_accuracy: 0.6597\n",
      "Epoch 7/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6375 - accuracy: 0.7490 - val_loss: 0.6447 - val_accuracy: 0.6875\n",
      "Epoch 8/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6202 - accuracy: 0.7707 - val_loss: 0.6296 - val_accuracy: 0.7153\n",
      "Epoch 9/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5998 - accuracy: 0.7954 - val_loss: 0.6127 - val_accuracy: 0.7222\n",
      "Epoch 10/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5764 - accuracy: 0.8201 - val_loss: 0.5936 - val_accuracy: 0.7361\n",
      "Epoch 11/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5495 - accuracy: 0.8347 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
      "Epoch 12/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.5201 - accuracy: 0.8502 - val_loss: 0.5522 - val_accuracy: 0.7500\n",
      "Epoch 13/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.4879 - accuracy: 0.8680 - val_loss: 0.5311 - val_accuracy: 0.7708\n",
      "Epoch 14/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.8780 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
      "Epoch 15/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8849 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
      "Epoch 16/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.3848 - accuracy: 0.8950 - val_loss: 0.4706 - val_accuracy: 0.7847\n",
      "Epoch 17/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.9120 - val_loss: 0.4557 - val_accuracy: 0.7847\n",
      "Epoch 18/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 0.9197 - val_loss: 0.4410 - val_accuracy: 0.7986\n",
      "Epoch 19/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2909 - accuracy: 0.9313 - val_loss: 0.4304 - val_accuracy: 0.7986\n",
      "Epoch 20/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2643 - accuracy: 0.9351 - val_loss: 0.4220 - val_accuracy: 0.8056\n",
      "Epoch 21/1000\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.9483 - val_loss: 0.4157 - val_accuracy: 0.8125\n",
      "Epoch 22/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2178 - accuracy: 0.9552 - val_loss: 0.4119 - val_accuracy: 0.8125\n",
      "Epoch 23/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1985 - accuracy: 0.9583 - val_loss: 0.4091 - val_accuracy: 0.8194\n",
      "Epoch 24/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.9622 - val_loss: 0.4085 - val_accuracy: 0.8056\n",
      "Epoch 25/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1657 - accuracy: 0.9637 - val_loss: 0.4074 - val_accuracy: 0.8125\n",
      "Epoch 26/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1521 - accuracy: 0.9653 - val_loss: 0.4079 - val_accuracy: 0.8194\n",
      "Epoch 27/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9707 - val_loss: 0.4095 - val_accuracy: 0.8056\n",
      "Epoch 28/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1293 - accuracy: 0.9714 - val_loss: 0.4141 - val_accuracy: 0.8056\n",
      "Epoch 29/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1195 - accuracy: 0.9722 - val_loss: 0.4146 - val_accuracy: 0.8125\n",
      "Epoch 30/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1112 - accuracy: 0.9784 - val_loss: 0.4181 - val_accuracy: 0.7986\n",
      "Epoch 31/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9784 - val_loss: 0.4234 - val_accuracy: 0.8056\n",
      "Epoch 32/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9792 - val_loss: 0.4253 - val_accuracy: 0.8125\n",
      "Epoch 33/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0898 - accuracy: 0.9792 - val_loss: 0.4297 - val_accuracy: 0.8125\n",
      "Epoch 34/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.9815 - val_loss: 0.4352 - val_accuracy: 0.8125\n",
      "Epoch 35/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.9815 - val_loss: 0.4409 - val_accuracy: 0.8194\n",
      "Epoch 36/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0745 - accuracy: 0.9830 - val_loss: 0.4436 - val_accuracy: 0.8125\n",
      "Epoch 37/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9838 - val_loss: 0.4481 - val_accuracy: 0.8056\n",
      "Epoch 38/1000\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.9853 - val_loss: 0.4539 - val_accuracy: 0.8194\n",
      "Epoch 39/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0626 - accuracy: 0.9861 - val_loss: 0.4578 - val_accuracy: 0.8056\n",
      "Epoch 40/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.4631 - val_accuracy: 0.8125\n",
      "Epoch 41/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0563 - accuracy: 0.9876 - val_loss: 0.4696 - val_accuracy: 0.8125\n",
      "Epoch 42/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0539 - accuracy: 0.9876 - val_loss: 0.4740 - val_accuracy: 0.8125\n",
      "Epoch 43/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.9892 - val_loss: 0.4782 - val_accuracy: 0.8125\n",
      "Epoch 44/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9900 - val_loss: 0.4842 - val_accuracy: 0.8056\n",
      "Epoch 45/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9900 - val_loss: 0.4902 - val_accuracy: 0.8056\n",
      "Epoch 46/1000\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9915 - val_loss: 0.4942 - val_accuracy: 0.8056\n",
      "Epoch 47/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9915 - val_loss: 0.4999 - val_accuracy: 0.8056\n",
      "Epoch 48/1000\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9915 - val_loss: 0.5044 - val_accuracy: 0.8056\n",
      "Epoch 49/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0393 - accuracy: 0.9915 - val_loss: 0.5092 - val_accuracy: 0.8056\n",
      "Epoch 50/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9915 - val_loss: 0.5184 - val_accuracy: 0.8056\n",
      "Epoch 51/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9915 - val_loss: 0.5209 - val_accuracy: 0.8056\n",
      "Epoch 52/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9915 - val_loss: 0.5222 - val_accuracy: 0.7986\n",
      "Epoch 53/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9923 - val_loss: 0.5296 - val_accuracy: 0.8056\n",
      "Epoch 54/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9923 - val_loss: 0.5337 - val_accuracy: 0.8056\n",
      "Epoch 55/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9931 - val_loss: 0.5358 - val_accuracy: 0.7986\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "==================\n",
      "F1: 0.82534\n",
      "Acc: 0.8255000000000001\n",
      "AUC: 0.9009199999999999\n",
      "==================\n",
      "Running => TfidfVectorizer(max_features=10000,\n",
      "                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f688e5ba850>>)\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 11ms/step - loss: 0.6934 - accuracy: 0.4821 - val_loss: 0.6935 - val_accuracy: 0.4966\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5373 - val_loss: 0.6929 - val_accuracy: 0.5101\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.5851 - val_loss: 0.6923 - val_accuracy: 0.5570\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.6216 - val_loss: 0.6913 - val_accuracy: 0.5705\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6874 - accuracy: 0.6396 - val_loss: 0.6899 - val_accuracy: 0.5839\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6843 - accuracy: 0.6709 - val_loss: 0.6875 - val_accuracy: 0.5973\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6800 - accuracy: 0.7224 - val_loss: 0.6842 - val_accuracy: 0.6040\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6744 - accuracy: 0.7500 - val_loss: 0.6797 - val_accuracy: 0.6644\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6677 - accuracy: 0.7537 - val_loss: 0.6741 - val_accuracy: 0.6846\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6599 - accuracy: 0.7836 - val_loss: 0.6687 - val_accuracy: 0.7181\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6515 - accuracy: 0.7955 - val_loss: 0.6608 - val_accuracy: 0.6980\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.8127 - val_loss: 0.6528 - val_accuracy: 0.7248\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6287 - accuracy: 0.8179 - val_loss: 0.6429 - val_accuracy: 0.7248\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6149 - accuracy: 0.8276 - val_loss: 0.6324 - val_accuracy: 0.7584\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.8396 - val_loss: 0.6198 - val_accuracy: 0.7517\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5805 - accuracy: 0.8530 - val_loss: 0.6058 - val_accuracy: 0.7517\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.5595 - accuracy: 0.8604 - val_loss: 0.5900 - val_accuracy: 0.7785\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5359 - accuracy: 0.8679 - val_loss: 0.5729 - val_accuracy: 0.7919\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5094 - accuracy: 0.8716 - val_loss: 0.5540 - val_accuracy: 0.7987\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4801 - accuracy: 0.8828 - val_loss: 0.5336 - val_accuracy: 0.7987\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.8918 - val_loss: 0.5128 - val_accuracy: 0.7785\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.9030 - val_loss: 0.4926 - val_accuracy: 0.8188\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.9119 - val_loss: 0.4723 - val_accuracy: 0.8322\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.9172 - val_loss: 0.4574 - val_accuracy: 0.8322\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.3182 - accuracy: 0.9284 - val_loss: 0.4352 - val_accuracy: 0.8456\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.2882 - accuracy: 0.9366 - val_loss: 0.4204 - val_accuracy: 0.8456\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2596 - accuracy: 0.9500 - val_loss: 0.4035 - val_accuracy: 0.8456\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.2329 - accuracy: 0.9552 - val_loss: 0.3905 - val_accuracy: 0.8456\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9597 - val_loss: 0.3785 - val_accuracy: 0.8456\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1871 - accuracy: 0.9634 - val_loss: 0.3717 - val_accuracy: 0.8389\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1680 - accuracy: 0.9701 - val_loss: 0.3558 - val_accuracy: 0.8456\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1504 - accuracy: 0.9746 - val_loss: 0.3482 - val_accuracy: 0.8456\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 0.9776 - val_loss: 0.3452 - val_accuracy: 0.8389\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1216 - accuracy: 0.9836 - val_loss: 0.3360 - val_accuracy: 0.8456\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1101 - accuracy: 0.9843 - val_loss: 0.3346 - val_accuracy: 0.8389\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0998 - accuracy: 0.9888 - val_loss: 0.3259 - val_accuracy: 0.8456\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0902 - accuracy: 0.9881 - val_loss: 0.3271 - val_accuracy: 0.8456\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0817 - accuracy: 0.9918 - val_loss: 0.3177 - val_accuracy: 0.8523\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9903 - val_loss: 0.3157 - val_accuracy: 0.8523\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9925 - val_loss: 0.3176 - val_accuracy: 0.8389\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9940 - val_loss: 0.3138 - val_accuracy: 0.8523\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9933 - val_loss: 0.3132 - val_accuracy: 0.8523\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 0.9955 - val_loss: 0.3109 - val_accuracy: 0.8523\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0476 - accuracy: 0.9955 - val_loss: 0.3144 - val_accuracy: 0.8389\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9963 - val_loss: 0.3126 - val_accuracy: 0.8389\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0405 - accuracy: 0.9970 - val_loss: 0.3153 - val_accuracy: 0.8389\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9970 - val_loss: 0.3128 - val_accuracy: 0.8389\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9970 - val_loss: 0.3207 - val_accuracy: 0.8456\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9978 - val_loss: 0.3121 - val_accuracy: 0.8456\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9970 - val_loss: 0.3113 - val_accuracy: 0.8523\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9978 - val_loss: 0.3117 - val_accuracy: 0.8523\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0266 - accuracy: 0.9978 - val_loss: 0.3128 - val_accuracy: 0.8523\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9985 - val_loss: 0.3132 - val_accuracy: 0.8523\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9985 - val_loss: 0.3158 - val_accuracy: 0.8523\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0220 - accuracy: 0.9993 - val_loss: 0.3165 - val_accuracy: 0.8523\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.8523\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.8591\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.8523\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.8523\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.8523\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.8389\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.8523\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.8591\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8523\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.8523\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.8523\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.8523\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.8523\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.8591\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.8591\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.8523\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.8591\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.8591\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "==================\n",
      "F1: 0.8286666666666666\n",
      "Acc: 0.8288166666666666\n",
      "AUC: 0.9068333333333333\n",
      "==================\n",
      "Running => TfidfVectorizer(max_features=10000, ngram_range=(1, 3),\n",
      "                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f688e5ba850>>)\n",
      "Epoch 1/1000\n",
      "41/41 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5027 - val_loss: 0.6891 - val_accuracy: 0.5103\n",
      "Epoch 2/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.5356 - val_loss: 0.6878 - val_accuracy: 0.5448\n",
      "Epoch 3/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6853 - accuracy: 0.6291 - val_loss: 0.6855 - val_accuracy: 0.6414\n",
      "Epoch 4/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6818 - accuracy: 0.6628 - val_loss: 0.6828 - val_accuracy: 0.7241\n",
      "Epoch 5/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6781 - accuracy: 0.7617 - val_loss: 0.6795 - val_accuracy: 0.7310\n",
      "Epoch 6/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6739 - accuracy: 0.7563 - val_loss: 0.6759 - val_accuracy: 0.7655\n",
      "Epoch 7/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6686 - accuracy: 0.8000 - val_loss: 0.6710 - val_accuracy: 0.7862\n",
      "Epoch 8/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6621 - accuracy: 0.8153 - val_loss: 0.6644 - val_accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6537 - accuracy: 0.8276 - val_loss: 0.6566 - val_accuracy: 0.8000\n",
      "Epoch 10/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.6432 - accuracy: 0.8452 - val_loss: 0.6463 - val_accuracy: 0.8138\n",
      "Epoch 11/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6303 - accuracy: 0.8559 - val_loss: 0.6345 - val_accuracy: 0.8276\n",
      "Epoch 12/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.6147 - accuracy: 0.8682 - val_loss: 0.6194 - val_accuracy: 0.8345\n",
      "Epoch 13/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.5960 - accuracy: 0.8858 - val_loss: 0.6021 - val_accuracy: 0.8345\n",
      "Epoch 14/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5743 - accuracy: 0.8881 - val_loss: 0.5812 - val_accuracy: 0.8483\n",
      "Epoch 15/1000\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.9019 - val_loss: 0.5580 - val_accuracy: 0.8483\n",
      "Epoch 16/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.5205 - accuracy: 0.9034 - val_loss: 0.5320 - val_accuracy: 0.8621\n",
      "Epoch 17/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.9073 - val_loss: 0.5083 - val_accuracy: 0.8345\n",
      "Epoch 18/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.9142 - val_loss: 0.4767 - val_accuracy: 0.8621\n",
      "Epoch 19/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.9226 - val_loss: 0.4488 - val_accuracy: 0.8621\n",
      "Epoch 20/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.9264 - val_loss: 0.4238 - val_accuracy: 0.8483\n",
      "Epoch 21/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.9326 - val_loss: 0.3940 - val_accuracy: 0.8690\n",
      "Epoch 22/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.9410 - val_loss: 0.3730 - val_accuracy: 0.8690\n",
      "Epoch 23/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2890 - accuracy: 0.9448 - val_loss: 0.3520 - val_accuracy: 0.8828\n",
      "Epoch 24/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2610 - accuracy: 0.9525 - val_loss: 0.3304 - val_accuracy: 0.9034\n",
      "Epoch 25/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2356 - accuracy: 0.9533 - val_loss: 0.3130 - val_accuracy: 0.9103\n",
      "Epoch 26/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.2128 - accuracy: 0.9648 - val_loss: 0.2992 - val_accuracy: 0.9103\n",
      "Epoch 27/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1926 - accuracy: 0.9640 - val_loss: 0.2867 - val_accuracy: 0.9103\n",
      "Epoch 28/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9701 - val_loss: 0.2720 - val_accuracy: 0.9103\n",
      "Epoch 29/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1577 - accuracy: 0.9739 - val_loss: 0.2626 - val_accuracy: 0.9103\n",
      "Epoch 30/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.1433 - accuracy: 0.9747 - val_loss: 0.2553 - val_accuracy: 0.9172\n",
      "Epoch 31/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1308 - accuracy: 0.9755 - val_loss: 0.2437 - val_accuracy: 0.9103\n",
      "Epoch 32/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.1195 - accuracy: 0.9785 - val_loss: 0.2378 - val_accuracy: 0.9172\n",
      "Epoch 33/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1094 - accuracy: 0.9816 - val_loss: 0.2311 - val_accuracy: 0.9241\n",
      "Epoch 34/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.1004 - accuracy: 0.9831 - val_loss: 0.2302 - val_accuracy: 0.9172\n",
      "Epoch 35/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0926 - accuracy: 0.9839 - val_loss: 0.2184 - val_accuracy: 0.9310\n",
      "Epoch 36/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0856 - accuracy: 0.9839 - val_loss: 0.2184 - val_accuracy: 0.9241\n",
      "Epoch 37/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0796 - accuracy: 0.9854 - val_loss: 0.2104 - val_accuracy: 0.9310\n",
      "Epoch 38/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9885 - val_loss: 0.2134 - val_accuracy: 0.9241\n",
      "Epoch 39/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.9885 - val_loss: 0.2037 - val_accuracy: 0.9310\n",
      "Epoch 40/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0646 - accuracy: 0.9893 - val_loss: 0.2009 - val_accuracy: 0.9310\n",
      "Epoch 41/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0607 - accuracy: 0.9916 - val_loss: 0.2007 - val_accuracy: 0.9241\n",
      "Epoch 42/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0572 - accuracy: 0.9908 - val_loss: 0.1960 - val_accuracy: 0.9310\n",
      "Epoch 43/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9923 - val_loss: 0.1925 - val_accuracy: 0.9310\n",
      "Epoch 44/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.9923 - val_loss: 0.1924 - val_accuracy: 0.9310\n",
      "Epoch 45/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9916 - val_loss: 0.1885 - val_accuracy: 0.9310\n",
      "Epoch 46/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0459 - accuracy: 0.9939 - val_loss: 0.1871 - val_accuracy: 0.9310\n",
      "Epoch 47/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9931 - val_loss: 0.1862 - val_accuracy: 0.9310\n",
      "Epoch 48/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0418 - accuracy: 0.9931 - val_loss: 0.1827 - val_accuracy: 0.9310\n",
      "Epoch 49/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9939 - val_loss: 0.1806 - val_accuracy: 0.9310\n",
      "Epoch 50/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9931 - val_loss: 0.1824 - val_accuracy: 0.9310\n",
      "Epoch 51/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 0.9939 - val_loss: 0.1806 - val_accuracy: 0.9310\n",
      "Epoch 52/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9939 - val_loss: 0.1800 - val_accuracy: 0.9310\n",
      "Epoch 53/1000\n",
      "41/41 [==============================] - 0s 10ms/step - loss: 0.0343 - accuracy: 0.9931 - val_loss: 0.1789 - val_accuracy: 0.9310\n",
      "Epoch 54/1000\n",
      "41/41 [==============================] - 1s 12ms/step - loss: 0.0332 - accuracy: 0.9931 - val_loss: 0.1763 - val_accuracy: 0.9379\n",
      "Epoch 55/1000\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.0321 - accuracy: 0.9939 - val_loss: 0.1783 - val_accuracy: 0.9310\n",
      "Epoch 56/1000\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.0308 - accuracy: 0.9946 - val_loss: 0.1775 - val_accuracy: 0.9379\n",
      "Epoch 57/1000\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.0299 - accuracy: 0.9946 - val_loss: 0.1761 - val_accuracy: 0.9379\n",
      "Epoch 58/1000\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 0.0291 - accuracy: 0.9962 - val_loss: 0.1767 - val_accuracy: 0.9379\n",
      "Epoch 59/1000\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.0281 - accuracy: 0.9962 - val_loss: 0.1745 - val_accuracy: 0.9448\n",
      "Epoch 60/1000\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0274 - accuracy: 0.9962 - val_loss: 0.1787 - val_accuracy: 0.9379\n",
      "Epoch 61/1000\n",
      "41/41 [==============================] - 1s 15ms/step - loss: 0.0266 - accuracy: 0.9954 - val_loss: 0.1774 - val_accuracy: 0.9379\n",
      "Epoch 62/1000\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.0259 - accuracy: 0.9962 - val_loss: 0.1721 - val_accuracy: 0.9448\n",
      "Epoch 63/1000\n",
      "41/41 [==============================] - 1s 12ms/step - loss: 0.0253 - accuracy: 0.9962 - val_loss: 0.1741 - val_accuracy: 0.9379\n",
      "Epoch 64/1000\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.0246 - accuracy: 0.9954 - val_loss: 0.1786 - val_accuracy: 0.9379\n",
      "Epoch 65/1000\n",
      "41/41 [==============================] - 1s 14ms/step - loss: 0.0243 - accuracy: 0.9954 - val_loss: 0.1771 - val_accuracy: 0.9379\n",
      "Epoch 66/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9962 - val_loss: 0.1721 - val_accuracy: 0.9448\n",
      "Epoch 67/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9954 - val_loss: 0.1707 - val_accuracy: 0.9448\n",
      "Epoch 68/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9962 - val_loss: 0.1733 - val_accuracy: 0.9448\n",
      "Epoch 69/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9954 - val_loss: 0.1738 - val_accuracy: 0.9379\n",
      "Epoch 70/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.1741 - val_accuracy: 0.9379\n",
      "Epoch 71/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.1725 - val_accuracy: 0.9448\n",
      "Epoch 72/1000\n",
      "41/41 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9962 - val_loss: 0.1724 - val_accuracy: 0.9448\n",
      "Epoch 73/1000\n",
      "41/41 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.1717 - val_accuracy: 0.9448\n",
      "Epoch 74/1000\n",
      "41/41 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9962 - val_loss: 0.1733 - val_accuracy: 0.9448\n",
      "Epoch 75/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.1696 - val_accuracy: 0.9448\n",
      "Epoch 76/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0199 - accuracy: 0.9969 - val_loss: 0.1744 - val_accuracy: 0.9379\n",
      "Epoch 77/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 0.1747 - val_accuracy: 0.9379\n",
      "Epoch 78/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9962 - val_loss: 0.1756 - val_accuracy: 0.9379\n",
      "Epoch 79/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.1749 - val_accuracy: 0.9379\n",
      "Epoch 80/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.1716 - val_accuracy: 0.9448\n",
      "Epoch 81/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.1705 - val_accuracy: 0.9379\n",
      "Epoch 82/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9962 - val_loss: 0.1747 - val_accuracy: 0.9379\n",
      "Epoch 83/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.1701 - val_accuracy: 0.9448\n",
      "Epoch 84/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.1680 - val_accuracy: 0.9448\n",
      "Epoch 85/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.1733 - val_accuracy: 0.9448\n",
      "Epoch 86/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 0.1727 - val_accuracy: 0.9448\n",
      "Epoch 87/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.1745 - val_accuracy: 0.9379\n",
      "Epoch 88/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.1731 - val_accuracy: 0.9448\n",
      "Epoch 89/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.1709 - val_accuracy: 0.9448\n",
      "Epoch 90/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.1735 - val_accuracy: 0.9448\n",
      "Epoch 91/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0168 - accuracy: 0.9962 - val_loss: 0.1715 - val_accuracy: 0.9379\n",
      "Epoch 92/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.1737 - val_accuracy: 0.9448\n",
      "Epoch 93/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.1748 - val_accuracy: 0.9448\n",
      "Epoch 94/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.1714 - val_accuracy: 0.9448\n",
      "Epoch 95/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.1778 - val_accuracy: 0.9310\n",
      "Epoch 96/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.1714 - val_accuracy: 0.9448\n",
      "Epoch 97/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.1720 - val_accuracy: 0.9448\n",
      "Epoch 98/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9969 - val_loss: 0.1741 - val_accuracy: 0.9379\n",
      "Epoch 99/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.1755 - val_accuracy: 0.9448\n",
      "Epoch 100/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1744 - val_accuracy: 0.9379\n",
      "Epoch 101/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.1733 - val_accuracy: 0.9379\n",
      "Epoch 102/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.1720 - val_accuracy: 0.9448\n",
      "Epoch 103/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.1737 - val_accuracy: 0.9379\n",
      "Epoch 104/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.1717 - val_accuracy: 0.9517\n",
      "Epoch 105/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.1731 - val_accuracy: 0.9448\n",
      "Epoch 106/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1724 - val_accuracy: 0.9517\n",
      "Epoch 107/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.1729 - val_accuracy: 0.9517\n",
      "Epoch 108/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.1710 - val_accuracy: 0.9517\n",
      "Epoch 109/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.1730 - val_accuracy: 0.9517\n",
      "Epoch 110/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.1737 - val_accuracy: 0.9448\n",
      "Epoch 111/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.1728 - val_accuracy: 0.9517\n",
      "Epoch 112/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.1744 - val_accuracy: 0.9448\n",
      "Epoch 113/1000\n",
      "41/41 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.1733 - val_accuracy: 0.9517\n",
      "Epoch 114/1000\n",
      "41/41 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.1741 - val_accuracy: 0.9517\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "==================\n",
      "F1: 0.8315571428571429\n",
      "Acc: 0.8317714285714286\n",
      "AUC: 0.9114285714285714\n",
      "==================\n",
      "Running => TfidfVectorizer(analyzer='char', max_features=10000, ngram_range=(1, 5))\n",
      "Epoch 1/1000\n",
      "43/43 [==============================] - 1s 11ms/step - loss: 0.6918 - accuracy: 0.5269 - val_loss: 0.6911 - val_accuracy: 0.4967\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.6826 - accuracy: 0.5991 - val_loss: 0.6844 - val_accuracy: 0.5497\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.6691 - accuracy: 0.6352 - val_loss: 0.6713 - val_accuracy: 0.5894\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.6457 - accuracy: 0.7222 - val_loss: 0.6479 - val_accuracy: 0.7285\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.6113 - accuracy: 0.8150 - val_loss: 0.6185 - val_accuracy: 0.7748\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.8445 - val_loss: 0.5840 - val_accuracy: 0.7947\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.8696 - val_loss: 0.5460 - val_accuracy: 0.8079\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.8873 - val_loss: 0.5055 - val_accuracy: 0.8079\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.9138 - val_loss: 0.4734 - val_accuracy: 0.7947\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3370 - accuracy: 0.9248 - val_loss: 0.4378 - val_accuracy: 0.8013\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2863 - accuracy: 0.9352 - val_loss: 0.4151 - val_accuracy: 0.8146\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2414 - accuracy: 0.9469 - val_loss: 0.3880 - val_accuracy: 0.8079\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2016 - accuracy: 0.9632 - val_loss: 0.3765 - val_accuracy: 0.8278\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 0.9713 - val_loss: 0.3626 - val_accuracy: 0.8278\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9779 - val_loss: 0.3599 - val_accuracy: 0.8344\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1197 - accuracy: 0.9845 - val_loss: 0.3465 - val_accuracy: 0.8344\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1001 - accuracy: 0.9889 - val_loss: 0.3449 - val_accuracy: 0.8344\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 0.9919 - val_loss: 0.3426 - val_accuracy: 0.8344\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0721 - accuracy: 0.9934 - val_loss: 0.3473 - val_accuracy: 0.8411\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.9963 - val_loss: 0.3424 - val_accuracy: 0.8411\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0521 - accuracy: 0.9971 - val_loss: 0.3497 - val_accuracy: 0.8411\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9978 - val_loss: 0.3494 - val_accuracy: 0.8543\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9985 - val_loss: 0.3508 - val_accuracy: 0.8543\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9993 - val_loss: 0.3586 - val_accuracy: 0.8477\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9993 - val_loss: 0.3570 - val_accuracy: 0.8477\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9993 - val_loss: 0.3761 - val_accuracy: 0.8477\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.8411\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.8411\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.8477\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8477\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.8609\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.8543\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.8477\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.8543\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.8609\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.8543\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.8609\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8543\n",
      "Epoch 39/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.8543\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8543\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.8543\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.8477\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.8543\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.8543\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8477\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.8543\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8477\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8543\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.8543\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8543\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "==================\n",
      "F1: 0.8305374999999999\n",
      "Acc: 0.830725\n",
      "AUC: 0.9112374999999999\n",
      "==================\n",
      "Running => TfidfVectorizer(analyzer='char', max_features=10000, ngram_range=(4, 5))\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.6899 - accuracy: 0.5103 - val_loss: 0.6839 - val_accuracy: 0.5306\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6800 - accuracy: 0.5513 - val_loss: 0.6771 - val_accuracy: 0.5374\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6669 - accuracy: 0.5702 - val_loss: 0.6675 - val_accuracy: 0.5646\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6488 - accuracy: 0.6317 - val_loss: 0.6543 - val_accuracy: 0.5986\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6245 - accuracy: 0.6902 - val_loss: 0.6373 - val_accuracy: 0.6190\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5937 - accuracy: 0.7206 - val_loss: 0.6131 - val_accuracy: 0.7279\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5572 - accuracy: 0.8193 - val_loss: 0.5878 - val_accuracy: 0.7687\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.8603 - val_loss: 0.5597 - val_accuracy: 0.8163\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4787 - accuracy: 0.8975 - val_loss: 0.5331 - val_accuracy: 0.8163\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.9157 - val_loss: 0.5045 - val_accuracy: 0.8231\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.9355 - val_loss: 0.4794 - val_accuracy: 0.8299\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3624 - accuracy: 0.9453 - val_loss: 0.4539 - val_accuracy: 0.8299\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.9575 - val_loss: 0.4311 - val_accuracy: 0.8435\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2925 - accuracy: 0.9643 - val_loss: 0.4102 - val_accuracy: 0.8503\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2609 - accuracy: 0.9749 - val_loss: 0.3924 - val_accuracy: 0.8503\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2315 - accuracy: 0.9856 - val_loss: 0.3771 - val_accuracy: 0.8503\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.2046 - accuracy: 0.9886 - val_loss: 0.3628 - val_accuracy: 0.8639\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1802 - accuracy: 0.9909 - val_loss: 0.3513 - val_accuracy: 0.8639\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1581 - accuracy: 0.9924 - val_loss: 0.3431 - val_accuracy: 0.8639\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1386 - accuracy: 0.9939 - val_loss: 0.3351 - val_accuracy: 0.8639\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9947 - val_loss: 0.3286 - val_accuracy: 0.8639\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1065 - accuracy: 0.9954 - val_loss: 0.3241 - val_accuracy: 0.8571\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0935 - accuracy: 0.9970 - val_loss: 0.3193 - val_accuracy: 0.8571\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9977 - val_loss: 0.3176 - val_accuracy: 0.8571\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0727 - accuracy: 0.9977 - val_loss: 0.3175 - val_accuracy: 0.8571\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9985 - val_loss: 0.3161 - val_accuracy: 0.8639\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0567 - accuracy: 0.9985 - val_loss: 0.3165 - val_accuracy: 0.8639\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.9992 - val_loss: 0.3134 - val_accuracy: 0.8571\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9992 - val_loss: 0.3160 - val_accuracy: 0.8639\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9992 - val_loss: 0.3162 - val_accuracy: 0.8639\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.8707\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.8707\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.8707\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.8707\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.8707\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.8707\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.8707\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.8707\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.8707\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.8707\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.8707\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.8707\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.8707\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.8707\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.8707\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.8707\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.8639\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.8639\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.8639\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.8707\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.8707\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.8707\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.8639\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.8639\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.8639\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.8639\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.8639\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.8639\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "==================\n",
      "F1: 0.8314222222222222\n",
      "Acc: 0.8316222222222223\n",
      "AUC: 0.9122777777777777\n",
      "==================\n",
      "Running => TfidfVectorizer(analyzer='char', max_features=10000, ngram_range=(3, 8))\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 11ms/step - loss: 0.6933 - accuracy: 0.5019 - val_loss: 0.6927 - val_accuracy: 0.5405\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6917 - accuracy: 0.5389 - val_loss: 0.6919 - val_accuracy: 0.5676\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6901 - accuracy: 0.5994 - val_loss: 0.6910 - val_accuracy: 0.5743\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6884 - accuracy: 0.6327 - val_loss: 0.6898 - val_accuracy: 0.6014\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6864 - accuracy: 0.6606 - val_loss: 0.6882 - val_accuracy: 0.6351\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6839 - accuracy: 0.7203 - val_loss: 0.6858 - val_accuracy: 0.6689\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6807 - accuracy: 0.7468 - val_loss: 0.6830 - val_accuracy: 0.7095\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.6766 - accuracy: 0.7740 - val_loss: 0.6792 - val_accuracy: 0.7297\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6712 - accuracy: 0.7884 - val_loss: 0.6737 - val_accuracy: 0.7500\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6638 - accuracy: 0.8057 - val_loss: 0.6667 - val_accuracy: 0.7568\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.6537 - accuracy: 0.8314 - val_loss: 0.6570 - val_accuracy: 0.7905\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.8488 - val_loss: 0.6431 - val_accuracy: 0.8243\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.6208 - accuracy: 0.8639 - val_loss: 0.6240 - val_accuracy: 0.8378\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.5942 - accuracy: 0.8874 - val_loss: 0.5978 - val_accuracy: 0.8581\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.5572 - accuracy: 0.8904 - val_loss: 0.5612 - val_accuracy: 0.8514\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.9078 - val_loss: 0.5136 - val_accuracy: 0.8649\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.9191 - val_loss: 0.4584 - val_accuracy: 0.8919\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.9305 - val_loss: 0.4022 - val_accuracy: 0.8986\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.3151 - accuracy: 0.9471 - val_loss: 0.3535 - val_accuracy: 0.9324\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.2581 - accuracy: 0.9615 - val_loss: 0.3118 - val_accuracy: 0.9324\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.2104 - accuracy: 0.9735 - val_loss: 0.2829 - val_accuracy: 0.9054\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.1725 - accuracy: 0.9781 - val_loss: 0.2574 - val_accuracy: 0.9122\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.1427 - accuracy: 0.9834 - val_loss: 0.2457 - val_accuracy: 0.9122\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.1191 - accuracy: 0.9864 - val_loss: 0.2284 - val_accuracy: 0.9054\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.1005 - accuracy: 0.9902 - val_loss: 0.2194 - val_accuracy: 0.9054\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0855 - accuracy: 0.9909 - val_loss: 0.2138 - val_accuracy: 0.9054\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0738 - accuracy: 0.9940 - val_loss: 0.2072 - val_accuracy: 0.9054\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0643 - accuracy: 0.9947 - val_loss: 0.2020 - val_accuracy: 0.9054\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.0567 - accuracy: 0.9962 - val_loss: 0.1990 - val_accuracy: 0.9054\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0499 - accuracy: 0.9955 - val_loss: 0.1982 - val_accuracy: 0.9054\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 0.9955 - val_loss: 0.1956 - val_accuracy: 0.9054\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9970 - val_loss: 0.1937 - val_accuracy: 0.9054\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9962 - val_loss: 0.1955 - val_accuracy: 0.9054\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9977 - val_loss: 0.1937 - val_accuracy: 0.9054\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9970 - val_loss: 0.1926 - val_accuracy: 0.9054\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9970 - val_loss: 0.1912 - val_accuracy: 0.9054\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9977 - val_loss: 0.1912 - val_accuracy: 0.9054\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9977 - val_loss: 0.1918 - val_accuracy: 0.9054\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 0.9977 - val_loss: 0.1907 - val_accuracy: 0.9054\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9977 - val_loss: 0.1928 - val_accuracy: 0.8986\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 0.9977 - val_loss: 0.1896 - val_accuracy: 0.9054\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9977 - val_loss: 0.1916 - val_accuracy: 0.8986\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 0.9977 - val_loss: 0.1923 - val_accuracy: 0.8986\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 0.9985 - val_loss: 0.1968 - val_accuracy: 0.8986\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9977 - val_loss: 0.1925 - val_accuracy: 0.8986\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0157 - accuracy: 0.9977 - val_loss: 0.1960 - val_accuracy: 0.8986\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.1949 - val_accuracy: 0.8986\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.9977 - val_loss: 0.1931 - val_accuracy: 0.8986\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 0.9985 - val_loss: 0.1943 - val_accuracy: 0.8986\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.1938 - val_accuracy: 0.8986\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.1949 - val_accuracy: 0.8986\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.1950 - val_accuracy: 0.8986\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 0.9985 - val_loss: 0.1948 - val_accuracy: 0.8986\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 0.1956 - val_accuracy: 0.8986\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.1960 - val_accuracy: 0.8986\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 0.1970 - val_accuracy: 0.8986\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.1966 - val_accuracy: 0.8986\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.1971 - val_accuracy: 0.8986\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.1976 - val_accuracy: 0.8986\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.1980 - val_accuracy: 0.8986\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.1981 - val_accuracy: 0.8986\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.2015 - val_accuracy: 0.8986\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.1994 - val_accuracy: 0.8986\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.2003 - val_accuracy: 0.8986\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.2000 - val_accuracy: 0.8986\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.1986 - val_accuracy: 0.9054\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.2010 - val_accuracy: 0.8986\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.2028 - val_accuracy: 0.8986\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.2027 - val_accuracy: 0.8986\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.2025 - val_accuracy: 0.8986\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.2040 - val_accuracy: 0.8986\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "==================\n",
      "F1: 0.8385199999999999\n",
      "Acc: 0.8387\n",
      "AUC: 0.91661\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "evaluation = list()\n",
    "usernames = list(np.unique(data[\"username\"]))\n",
    "results = list()\n",
    "\n",
    "for i, vectorizer in enumerate(vectorizers):\n",
    "    vectorizer_str = vectorizer.__str__()\n",
    "    print(f\"Running => {vectorizer_str}\")\n",
    "\n",
    "    for i in range(len(usernames)):\n",
    "        author1 = usernames.pop()\n",
    "\n",
    "        for author2 in usernames:\n",
    "            X_train, X_test, y_train, y_test = temporal_train_test_split(\n",
    "                data, author1, author2)\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = vectorizer.fit_transform(X_train[\"comment\"]).toarray()\n",
    "            X_test = vectorizer.transform(X_test[\"comment\"]).toarray()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            y_classes = pd.get_dummies(y_train).columns\n",
    "            y_train = pd.get_dummies(y_train).values\n",
    "            y_test = pd.get_dummies(y_test).values\n",
    "            \n",
    "            input_shape_text = X_train.shape[1]\n",
    "            output_shape = y_train.shape[1]\n",
    "\n",
    "            callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "            model = build_model(input_shape_text, output_shape)\n",
    "            model.compile(loss = \"categorical_crossentropy\",\n",
    "                        optimizer = keras.optimizers.SGD(learning_rate=0.01),\n",
    "                        metrics = [\"accuracy\"])\n",
    "            history = model.fit(X_train, y_train, epochs=1000, callbacks=[callback], validation_split=0.1, shuffle=True, verbose=True)\n",
    "\n",
    "\n",
    "            y_pred_proba = model.predict(X_test)\n",
    "            evaluation.append(evaluate_keras(y_test.argmax(1), y_pred_proba, *y_classes))\n",
    "    metrics = pd.DataFrame(evaluation)[[\"f1_macro\", \"recall_macro\", \"precision_macro\", \"accuracy\", \"auc_score\"]].mean()\n",
    "    metrics[\"vectorizer\"] = [vectorizer_str for i in range(len(metrics))]\n",
    "    results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>vectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.875800</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.877600</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.928600</td>\n",
       "      <td>[CountVectorizer(max_features=10000,\\n        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851400</td>\n",
       "      <td>0.851450</td>\n",
       "      <td>0.853750</td>\n",
       "      <td>0.851650</td>\n",
       "      <td>0.916100</td>\n",
       "      <td>[CountVectorizer(max_features=10000, ngram_ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841600</td>\n",
       "      <td>0.842467</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.841767</td>\n",
       "      <td>0.911567</td>\n",
       "      <td>[CountVectorizer(analyzer='char', max_features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830075</td>\n",
       "      <td>0.830825</td>\n",
       "      <td>0.832025</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>0.904425</td>\n",
       "      <td>[CountVectorizer(analyzer='char', max_features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.825340</td>\n",
       "      <td>0.826420</td>\n",
       "      <td>0.827960</td>\n",
       "      <td>0.825500</td>\n",
       "      <td>0.900920</td>\n",
       "      <td>[CountVectorizer(analyzer='char', max_features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.829583</td>\n",
       "      <td>0.830983</td>\n",
       "      <td>0.828817</td>\n",
       "      <td>0.906833</td>\n",
       "      <td>[TfidfVectorizer(max_features=10000,\\n        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.831557</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>0.833914</td>\n",
       "      <td>0.831771</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>[TfidfVectorizer(max_features=10000, ngram_ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.830537</td>\n",
       "      <td>0.831163</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>0.830725</td>\n",
       "      <td>0.911237</td>\n",
       "      <td>[TfidfVectorizer(analyzer='char', max_features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.831422</td>\n",
       "      <td>0.831967</td>\n",
       "      <td>0.833367</td>\n",
       "      <td>0.831622</td>\n",
       "      <td>0.912278</td>\n",
       "      <td>[TfidfVectorizer(analyzer='char', max_features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.838520</td>\n",
       "      <td>0.839030</td>\n",
       "      <td>0.840290</td>\n",
       "      <td>0.838700</td>\n",
       "      <td>0.916610</td>\n",
       "      <td>[TfidfVectorizer(analyzer='char', max_features...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_macro  recall_macro  precision_macro  accuracy  auc_score  \\\n",
       "0  0.875800      0.875600         0.877600  0.876000   0.928600   \n",
       "1  0.851400      0.851450         0.853750  0.851650   0.916100   \n",
       "2  0.841600      0.842467         0.844000  0.841767   0.911567   \n",
       "3  0.830075      0.830825         0.832025  0.830200   0.904425   \n",
       "4  0.825340      0.826420         0.827960  0.825500   0.900920   \n",
       "5  0.828667      0.829583         0.830983  0.828817   0.906833   \n",
       "6  0.831557      0.832271         0.833914  0.831771   0.911429   \n",
       "7  0.830537      0.831163         0.832600  0.830725   0.911237   \n",
       "8  0.831422      0.831967         0.833367  0.831622   0.912278   \n",
       "9  0.838520      0.839030         0.840290  0.838700   0.916610   \n",
       "\n",
       "                                          vectorizer  \n",
       "0  [CountVectorizer(max_features=10000,\\n        ...  \n",
       "1  [CountVectorizer(max_features=10000, ngram_ran...  \n",
       "2  [CountVectorizer(analyzer='char', max_features...  \n",
       "3  [CountVectorizer(analyzer='char', max_features...  \n",
       "4  [CountVectorizer(analyzer='char', max_features...  \n",
       "5  [TfidfVectorizer(max_features=10000,\\n        ...  \n",
       "6  [TfidfVectorizer(max_features=10000, ngram_ran...  \n",
       "7  [TfidfVectorizer(analyzer='char', max_features...  \n",
       "8  [TfidfVectorizer(analyzer='char', max_features...  \n",
       "9  [TfidfVectorizer(analyzer='char', max_features...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([results[i][:-1] for i in range(len(results))])\n",
    "metrics_df[\"vectorizer\"] = [results[i][-1] for i in range(len(results))]\n",
    "metrics_df.to_csv(\"../../results/neural_network.csv\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2961734913207ee881f462d4bc826f1f53aa8b6216ab04f585499525ca3800dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('reddit-in-portuguese-Kyc7Ejcc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

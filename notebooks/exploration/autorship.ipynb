{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Reddit.db')\n",
    "\n",
    "brasildob = pd.read_sql_query(\"\"\"\n",
    "SELECT Author.username, \n",
    "\t   Comment.body,\n",
    "\t   Subreddit.name AS subreddit_name, \n",
    "\t   Comment.created_utc\n",
    "FROM Comment\n",
    "INNER JOIN Author ON Author.id = Comment.author_id\n",
    "INNER JOIN Subreddit ON Comment.subreddit_id = Subreddit.id\n",
    "WHERE Author.username = 'squiercg'\n",
    "\"\"\", conn)\n",
    "\n",
    "brasil = pd.read_sql_query(\"\"\"\n",
    "SELECT Author.username, \n",
    "\t   Comment.body,\n",
    "\t   Subreddit.name AS subreddit_name, \n",
    "\t   Comment.created_utc\n",
    "FROM Comment\n",
    "INNER JOIN Author ON Author.id = Comment.author_id\n",
    "INNER JOIN Subreddit ON Comment.subreddit_id = Subreddit.id\n",
    "WHERE Author.username = 'AlehCemy'\n",
    "\"\"\", conn)\n",
    "\n",
    "brasilivre = pd.read_sql_query(\"\"\"\n",
    "SELECT Author.username, \n",
    "\t   Comment.body,\n",
    "\t   Subreddit.name AS subreddit_name, \n",
    "\t   Comment.created_utc\n",
    "FROM Comment\n",
    "INNER JOIN Author ON Author.id = Comment.author_id\n",
    "INNER JOIN Subreddit ON Comment.subreddit_id = Subreddit.id\n",
    "WHERE Author.username = 'drfritz2'\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_brasilivre = brasilivre[:200]\n",
    "test_brasildob = brasildob[:200]\n",
    "train_brasilivre = brasilivre[200:]\n",
    "train_brasildob = brasildob[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_brasildob, train_brasilivre], ignore_index=True, sort=False)\n",
    "test = pd.concat([test_brasilivre, test_brasildob], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.pt.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_texts_train = [nlp(text) for text in train.body]\n",
    "pos_texts_test = [nlp(text) for text in test.body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train = np.empty(len(pos_texts_train), dtype='object')\n",
    "for i in range(len(pos_texts_train)):\n",
    "    pos_train[i] = \" \".join([token.pos_ for token in pos_texts_train[i]])\n",
    "\n",
    "pos_test = np.empty(len(pos_texts_test), dtype='object')\n",
    "for i in range(len(pos_texts_test)):\n",
    "    pos_test[i] = \" \".join([token.pos_ for token in pos_texts_test[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tfidf = TfidfVectorizer().fit(train.body)\n",
    "pos_tfidf = TfidfVectorizer().fit(pos_train)\n",
    "X_text_train = text_tfidf.transform(train.body)\n",
    "X_pos_train = pos_tfidf.transform(pos_train)\n",
    "y_train_full = pd.get_dummies(train.username).values\n",
    "y_classes = pd.get_dummies(train.username).columns\n",
    "\n",
    "X_text_test = text_tfidf.transform(test.body)\n",
    "X_pos_test = pos_tfidf.transform(pos_test)\n",
    "y_test = pd.get_dummies(test.username).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
    "    X_text_train, y_train_full, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_pos, X_val_pos, y_train, y_val = train_test_split(\n",
    "    X_pos_train, y_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_pos = X_train_pos.shape[1]\n",
    "input_shape_text = X_train_text.shape[1]\n",
    "output_shape = y_train_full.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape_pos, input_shape_text, output_shape):  \n",
    "    pos_input = keras.layers.Input(shape=input_shape_pos, name=\"Input_POS\")\n",
    "    text_input = keras.layers.Input(shape=input_shape_text, name=\"Input_Text\")\n",
    "\n",
    "    pos_dense1 = keras.layers.Dense(30, activation=\"relu\", name=\"Dense1_POS\")(pos_input)\n",
    "    text_dense1 = keras.layers.Dense(30, activation=\"relu\", name=\"Dense1_Text\")(text_input)\n",
    "    pos_dense2 = keras.layers.Dense(30, activation=\"relu\", name=\"Dense2_POS\")(pos_dense1)\n",
    "    text_dense2 = keras.layers.Dense(30, activation=\"relu\", name=\"Dense2_Text\")(text_dense1)\n",
    "    pos_dense3 = keras.layers.Dense(30, activation=\"relu\", name=\"Dense3_POS\")(pos_dense2)\n",
    "    text_dense3 = keras.layers.Dense(30, activation=\"relu\", name=\"Dense3_Text\")(text_dense2)\n",
    "\n",
    "    concat = keras.layers.concatenate([pos_dense3, text_dense3])\n",
    "    output = keras.layers.Dense(output_shape, activation=\"softmax\", name=\"Output\")(concat)\n",
    "    \n",
    "    model = keras.Model(inputs=[pos_input, text_input], outputs=[output])\n",
    "    #print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 19:39:03.521629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-23 19:39:03.594440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-02-23 19:39:03.594466: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-23 19:39:03.595011: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 6ms/step - loss: 0.6990 - accuracy: 0.4186 - val_loss: 0.6980 - val_accuracy: 0.4608\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.4709 - val_loss: 0.6957 - val_accuracy: 0.4835\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4903 - val_loss: 0.6941 - val_accuracy: 0.5038\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5148 - val_loss: 0.6925 - val_accuracy: 0.5443\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5350 - val_loss: 0.6900 - val_accuracy: 0.5114\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5325 - val_loss: 0.6882 - val_accuracy: 0.5241\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5156 - val_loss: 0.6867 - val_accuracy: 0.5899\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5755 - val_loss: 0.6846 - val_accuracy: 0.5367\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.5401 - val_loss: 0.6828 - val_accuracy: 0.5443\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5468 - val_loss: 0.6809 - val_accuracy: 0.5544\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5840 - val_loss: 0.6797 - val_accuracy: 0.6658\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6380 - val_loss: 0.6780 - val_accuracy: 0.6835\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.6608 - val_loss: 0.6754 - val_accuracy: 0.6101\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.6354 - val_loss: 0.6733 - val_accuracy: 0.6101\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6405 - val_loss: 0.6724 - val_accuracy: 0.7063\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6785 - val_loss: 0.6692 - val_accuracy: 0.7013\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.6895 - val_loss: 0.6675 - val_accuracy: 0.7114\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.6937 - val_loss: 0.6644 - val_accuracy: 0.6911\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.7021 - val_loss: 0.6629 - val_accuracy: 0.6987\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.7097 - val_loss: 0.6608 - val_accuracy: 0.7038\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.6996 - val_loss: 0.6557 - val_accuracy: 0.7544\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.7249 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7266 - val_loss: 0.6504 - val_accuracy: 0.7063\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.7283 - val_loss: 0.6464 - val_accuracy: 0.7114\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.7257 - val_loss: 0.6414 - val_accuracy: 0.7722\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7612 - val_loss: 0.6392 - val_accuracy: 0.7215\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.7451 - val_loss: 0.6344 - val_accuracy: 0.7544\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7620 - val_loss: 0.6314 - val_accuracy: 0.7089\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7578 - val_loss: 0.6235 - val_accuracy: 0.7797\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7705 - val_loss: 0.6193 - val_accuracy: 0.7443\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7586 - val_loss: 0.6135 - val_accuracy: 0.7494\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7662 - val_loss: 0.6073 - val_accuracy: 0.7873\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7865 - val_loss: 0.6019 - val_accuracy: 0.7873\n",
      "Epoch 34/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7966 - val_loss: 0.5994 - val_accuracy: 0.7241\n",
      "Epoch 35/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7857 - val_loss: 0.5884 - val_accuracy: 0.7671\n",
      "Epoch 36/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.8008 - val_loss: 0.5849 - val_accuracy: 0.7392\n",
      "Epoch 37/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7966 - val_loss: 0.5741 - val_accuracy: 0.7747\n",
      "Epoch 38/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.8118 - val_loss: 0.5712 - val_accuracy: 0.7620\n",
      "Epoch 39/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8000 - val_loss: 0.5570 - val_accuracy: 0.7873\n",
      "Epoch 40/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.8135 - val_loss: 0.5567 - val_accuracy: 0.7544\n",
      "Epoch 41/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.8110 - val_loss: 0.5388 - val_accuracy: 0.8228\n",
      "Epoch 42/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.8354 - val_loss: 0.5309 - val_accuracy: 0.7949\n",
      "Epoch 43/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8270 - val_loss: 0.5232 - val_accuracy: 0.8076\n",
      "Epoch 44/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8371 - val_loss: 0.5199 - val_accuracy: 0.7848\n",
      "Epoch 45/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8405 - val_loss: 0.4975 - val_accuracy: 0.8430\n",
      "Epoch 46/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8515 - val_loss: 0.4978 - val_accuracy: 0.8076\n",
      "Epoch 47/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.8489 - val_loss: 0.4796 - val_accuracy: 0.8354\n",
      "Epoch 48/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.8557 - val_loss: 0.4699 - val_accuracy: 0.8354\n",
      "Epoch 49/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8700 - val_loss: 0.4696 - val_accuracy: 0.8203\n",
      "Epoch 50/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8658 - val_loss: 0.4448 - val_accuracy: 0.8658\n",
      "Epoch 51/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8776 - val_loss: 0.4391 - val_accuracy: 0.8608\n",
      "Epoch 52/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8886 - val_loss: 0.4236 - val_accuracy: 0.8684\n",
      "Epoch 53/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8903 - val_loss: 0.4129 - val_accuracy: 0.8785\n",
      "Epoch 54/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8954 - val_loss: 0.4052 - val_accuracy: 0.8633\n",
      "Epoch 55/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.9030 - val_loss: 0.4081 - val_accuracy: 0.8582\n",
      "Epoch 56/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.9046 - val_loss: 0.3890 - val_accuracy: 0.8582\n",
      "Epoch 57/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.9089 - val_loss: 0.4080 - val_accuracy: 0.8329\n",
      "Epoch 58/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.9156 - val_loss: 0.3675 - val_accuracy: 0.8962\n",
      "Epoch 59/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.9190 - val_loss: 0.3565 - val_accuracy: 0.8835\n",
      "Epoch 60/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.9241 - val_loss: 0.4571 - val_accuracy: 0.7570\n",
      "Epoch 61/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.9224 - val_loss: 0.3382 - val_accuracy: 0.8911\n",
      "Epoch 62/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.9435 - val_loss: 0.3541 - val_accuracy: 0.8456\n",
      "Epoch 63/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.9384 - val_loss: 0.3340 - val_accuracy: 0.8709\n",
      "Epoch 64/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2410 - accuracy: 0.9451 - val_loss: 0.4228 - val_accuracy: 0.7899\n",
      "Epoch 65/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.9426 - val_loss: 0.4450 - val_accuracy: 0.7671\n",
      "Epoch 66/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9511 - val_loss: 0.3172 - val_accuracy: 0.8987\n",
      "Epoch 67/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9586 - val_loss: 0.3553 - val_accuracy: 0.8582\n",
      "Epoch 68/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1982 - accuracy: 0.9561 - val_loss: 0.3724 - val_accuracy: 0.8329\n",
      "Epoch 69/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9578 - val_loss: 0.3160 - val_accuracy: 0.8734\n",
      "Epoch 70/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9671 - val_loss: 0.3001 - val_accuracy: 0.8937\n",
      "Epoch 71/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9662 - val_loss: 0.2756 - val_accuracy: 0.9013\n",
      "Epoch 72/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9738 - val_loss: 0.3410 - val_accuracy: 0.8684\n",
      "Epoch 73/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9730 - val_loss: 0.2634 - val_accuracy: 0.9063\n",
      "Epoch 74/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9755 - val_loss: 0.2595 - val_accuracy: 0.9038\n",
      "Epoch 75/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9789 - val_loss: 0.2559 - val_accuracy: 0.9063\n",
      "Epoch 76/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9789 - val_loss: 0.2632 - val_accuracy: 0.8962\n",
      "Epoch 77/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9831 - val_loss: 0.2544 - val_accuracy: 0.9089\n",
      "Epoch 78/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9823 - val_loss: 0.2521 - val_accuracy: 0.9114\n",
      "Epoch 79/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9873 - val_loss: 0.2458 - val_accuracy: 0.9139\n",
      "Epoch 80/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9848 - val_loss: 0.2431 - val_accuracy: 0.9139\n",
      "Epoch 81/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9890 - val_loss: 0.2649 - val_accuracy: 0.8861\n",
      "Epoch 82/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9882 - val_loss: 0.2393 - val_accuracy: 0.9165\n",
      "Epoch 83/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9916 - val_loss: 0.2397 - val_accuracy: 0.9165\n",
      "Epoch 84/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9916 - val_loss: 0.2333 - val_accuracy: 0.9114\n",
      "Epoch 85/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9941 - val_loss: 0.2945 - val_accuracy: 0.8759\n",
      "Epoch 86/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9932 - val_loss: 0.2499 - val_accuracy: 0.9038\n",
      "Epoch 87/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9949 - val_loss: 0.2287 - val_accuracy: 0.9089\n",
      "Epoch 88/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9958 - val_loss: 0.2327 - val_accuracy: 0.9038\n",
      "Epoch 89/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9966 - val_loss: 0.2637 - val_accuracy: 0.8886\n",
      "Epoch 90/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9958 - val_loss: 0.2276 - val_accuracy: 0.9139\n",
      "Epoch 91/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9966 - val_loss: 0.2976 - val_accuracy: 0.8759\n",
      "Epoch 92/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9966 - val_loss: 0.2249 - val_accuracy: 0.9139\n",
      "Epoch 93/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9975 - val_loss: 0.2238 - val_accuracy: 0.9190\n",
      "Epoch 94/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9958 - val_loss: 0.2231 - val_accuracy: 0.9114\n",
      "Epoch 95/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9975 - val_loss: 0.2312 - val_accuracy: 0.9063\n",
      "Epoch 96/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9966 - val_loss: 0.2231 - val_accuracy: 0.9165\n",
      "Epoch 97/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9975 - val_loss: 0.2218 - val_accuracy: 0.9114\n",
      "Epoch 98/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9966 - val_loss: 0.2267 - val_accuracy: 0.9165\n",
      "Epoch 99/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9975 - val_loss: 0.2223 - val_accuracy: 0.9089\n",
      "Epoch 100/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9966 - val_loss: 0.5080 - val_accuracy: 0.8000\n",
      "Epoch 101/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9958 - val_loss: 0.2222 - val_accuracy: 0.9063\n",
      "Epoch 102/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9975 - val_loss: 0.2639 - val_accuracy: 0.8861\n",
      "Epoch 103/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9958 - val_loss: 0.2202 - val_accuracy: 0.9190\n",
      "Epoch 104/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9983 - val_loss: 0.2365 - val_accuracy: 0.9063\n",
      "Epoch 105/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9975 - val_loss: 0.2205 - val_accuracy: 0.9190\n",
      "Epoch 106/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9975 - val_loss: 0.2199 - val_accuracy: 0.9089\n",
      "Epoch 107/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9966 - val_loss: 0.2212 - val_accuracy: 0.9165\n",
      "Epoch 108/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9975 - val_loss: 0.2224 - val_accuracy: 0.9165\n",
      "Epoch 109/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9992 - val_loss: 0.2580 - val_accuracy: 0.8886\n",
      "Epoch 110/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9975 - val_loss: 0.2209 - val_accuracy: 0.9089\n",
      "Epoch 111/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9992 - val_loss: 0.2269 - val_accuracy: 0.9165\n",
      "Epoch 112/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9992 - val_loss: 0.2210 - val_accuracy: 0.9165\n",
      "Epoch 113/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9983 - val_loss: 0.2210 - val_accuracy: 0.9190\n",
      "Epoch 114/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9983 - val_loss: 0.2245 - val_accuracy: 0.9139\n",
      "Epoch 115/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9992 - val_loss: 0.2223 - val_accuracy: 0.9089\n",
      "Epoch 116/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9983 - val_loss: 0.2221 - val_accuracy: 0.9165\n",
      "Epoch 117/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9992 - val_loss: 0.2229 - val_accuracy: 0.9139\n",
      "Epoch 118/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9983 - val_loss: 0.2245 - val_accuracy: 0.9114\n",
      "Epoch 119/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9992 - val_loss: 0.2223 - val_accuracy: 0.9089\n",
      "Epoch 120/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9983 - val_loss: 0.2230 - val_accuracy: 0.9165\n",
      "Epoch 121/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9983 - val_loss: 0.2229 - val_accuracy: 0.9089\n",
      "Epoch 122/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9983 - val_loss: 0.2232 - val_accuracy: 0.9114\n",
      "Epoch 123/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9983 - val_loss: 0.2242 - val_accuracy: 0.9165\n",
      "Epoch 124/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9992 - val_loss: 0.2238 - val_accuracy: 0.9089\n",
      "Epoch 125/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9983 - val_loss: 0.2316 - val_accuracy: 0.9190\n",
      "Epoch 126/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 0.2241 - val_accuracy: 0.9089\n",
      "Epoch 127/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9983 - val_loss: 0.2245 - val_accuracy: 0.9114\n",
      "Epoch 128/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9992 - val_loss: 0.2252 - val_accuracy: 0.9139\n",
      "Epoch 129/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9992 - val_loss: 0.2341 - val_accuracy: 0.9190\n",
      "Epoch 130/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9992 - val_loss: 0.2258 - val_accuracy: 0.9114\n",
      "Epoch 131/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9992 - val_loss: 0.2262 - val_accuracy: 0.9114\n",
      "Epoch 132/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9992 - val_loss: 0.2288 - val_accuracy: 0.9114\n",
      "Epoch 133/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9992 - val_loss: 0.2267 - val_accuracy: 0.9089\n",
      "Epoch 134/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9992 - val_loss: 0.2299 - val_accuracy: 0.9114\n",
      "Epoch 135/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.2273 - val_accuracy: 0.9089\n",
      "Epoch 136/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 0.2287 - val_accuracy: 0.9089\n"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "\n",
    "model = build_model(input_shape_pos, input_shape_text, output_shape)\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "             optimizer = keras.optimizers.SGD(learning_rate=0.01),\n",
    "             metrics = [\"accuracy\"])\n",
    "history = model.fit((X_train_pos.toarray(), X_train_text.toarray()), y_train, epochs=1000, validation_data=((X_val_pos.toarray(), X_val_text.toarray()), y_val), callbacks=[callback], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33289310336112976, 0.875]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate((X_pos_test.toarray(), X_text_test.toarray()), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

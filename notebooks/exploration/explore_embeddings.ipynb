{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import pickle\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Reddit.db')\n",
    "\n",
    "brasildob = pd.read_sql_query(\"\"\"\n",
    "select Comment.body, Subreddit.name from Comment\n",
    "INNER JOIN Subreddit ON Comment.subreddit_id = Subreddit.id\n",
    "WHERE Subreddit.name=\"BrasildoB\"\n",
    "\"\"\", conn)\n",
    "\n",
    "brasil = pd.read_sql_query(\"\"\"\n",
    "select Comment.body, Subreddit.name from Comment\n",
    "INNER JOIN Subreddit ON Comment.subreddit_id = Subreddit.id\n",
    "WHERE Subreddit.name=\"brasil\"\n",
    "\"\"\", conn)\n",
    "\n",
    "brasilivre = pd.read_sql_query(\"\"\"\n",
    "select Comment.body, Subreddit.name from Comment\n",
    "INNER JOIN Subreddit ON Comment.subreddit_id = Subreddit.id\n",
    "WHERE Subreddit.name=\"brasilivre\"\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = pd.concat([brasil, brasilivre, brasildob])\n",
    "X, y = RandomUnderSampler().fit_resample(bigdata.body.to_numpy().reshape(-1,1), bigdata.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata = pd.DataFrame({\"body\":X.flatten(), \"subreddit\":y})\n",
    "#bigdata = bigdata.sample(n=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(tokenizer=TweetTokenizer().tokenize)\n",
    "vect.fit(bigdata.body)\n",
    "tfidf_dict = dict(zip(vect.get_feature_names(), vect.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "\n",
    "texts = bigdata.body.str.lower()\n",
    "#texts = texts.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "X = texts.apply(tknzr.tokenize)\n",
    "\n",
    "emb = Word2Vec(X, vector_size=100, min_count=1, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "labels = []\n",
    "\n",
    "for word in list(emb.wv.key_to_index):\n",
    "  tokens.append(emb.wv[word])\n",
    "  labels.append(word)\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "new_values = pca.fit_transform(tokens)\n",
    "tsne = TSNE(perplexity=40, n_components=2)\n",
    "new_values = tsne.fit_transform(new_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(new_values[:,0], new_values[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_transform(X, tfidf, w2v):\n",
    "    docs_vectors = pd.DataFrame()\n",
    "    for doc in X:\n",
    "      temp = pd.DataFrame()\n",
    "      for word in doc:\n",
    "        try:\n",
    "          word_vec = tfidf[word] * w2v.wv[word]\n",
    "          temp = pd.concat([temp, pd.DataFrame([word_vec])], ignore_index = True)\n",
    "        except:\n",
    "          pass\n",
    "      doc_vector = temp.mean()\n",
    "      docs_vectors = pd.concat([docs_vectors, pd.DataFrame([doc_vector])], ignore_index = True)\n",
    "    return docs_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = embedding_transform(X.iloc, tfidf_dict, emb)\n",
    "X_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_na = list(X_emb[X_emb.isna().any(axis=1)].index)\n",
    "indexes_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb.drop(indexes_na, inplace=True)\n",
    "bigdata = bigdata.reset_index().drop(indexes_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(bigdata, open(\"bigdata.pickle\", \"wb\"))\n",
    "bigdata = pickle.load(open(\"bigdata.pickle\", \"rb\"))\n",
    "bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca_data = pca.fit_transform(X_emb)\n",
    "tsne = TSNE(perplexity=40, n_components=3)\n",
    "tsne_data = tsne.fit_transform(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_data = pd.DataFrame({\"Attr1\":tsne_data[:,0],\n",
    "                        \"Attr2\":tsne_data[:,1],\n",
    "                        'body':bigdata.body,\n",
    "                        \"subreddit\":bigdata.subreddit})\n",
    "\n",
    "pickle.dump(emb_data, open(\"emb_data_pca_tsne.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = emb_data #emb_data[emb_data.subreddit != \"brasil\"]\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(\"Attr1\", \"Attr2\", hue=\"subreddit\", data=to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly\n",
    "\n",
    "fig = px.scatter(emb_data, \n",
    "                 x=\"Attr1\", \n",
    "                 y=\"Attr2\", \n",
    "                 hover_data = ['body'],\n",
    "                 color=\"subreddit\", \n",
    "                 symbol='subreddit')\n",
    "plotly.offline.plot(fig, filename='fig.html')\n",
    "#fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(to_plot.subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(\"Attr1\", hue=\"subreddit\", data=to_plot)\n",
    "sns.kdeplot(\"Attr2\", hue=\"subreddit\", data=to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=to_plot.subreddit, y=to_plot.Attr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=to_plot.subreddit, y=to_plot.Attr2)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

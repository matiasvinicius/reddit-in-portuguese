{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `authors_pos.csv` to build the same classifiers used in word2vec, and same vectorizers form tfidf and count, being that we just analyze words now (POS tagging), including unigrams, bigrams etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../libs')\n",
    "from utils import get_data, temporal_train_test_split\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../libs')\n",
    "from utils import temporal_train_test_split\n",
    "from autorship import AuthorClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !python -m spacy download pt_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manada_2</td>\n",
       "      <td>2022-03-09 14:17:46+00:00</td>\n",
       "      <td>PROPN ADP NOUN ADJ PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BluePirate89</td>\n",
       "      <td>2022-03-31 16:00:06+00:00</td>\n",
       "      <td>NOUN PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9-Cortes</td>\n",
       "      <td>2021-11-29 02:08:23+00:00</td>\n",
       "      <td>NOUN ADJ PUNCT ADV DET ADJ NOUN PUNCT ADV DET ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Supermunch2000</td>\n",
       "      <td>2021-12-21 12:01:05+00:00</td>\n",
       "      <td>PROPN NOUN X VERB ADJ PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheGza1</td>\n",
       "      <td>2021-08-10 12:49:03+00:00</td>\n",
       "      <td>ADV VERB ADP NOUN PRON PRON VERB PUNCT DET NOU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                created_utc  \\\n",
       "0        Manada_2  2022-03-09 14:17:46+00:00   \n",
       "1    BluePirate89  2022-03-31 16:00:06+00:00   \n",
       "2        9-Cortes  2021-11-29 02:08:23+00:00   \n",
       "3  Supermunch2000  2021-12-21 12:01:05+00:00   \n",
       "4         TheGza1  2021-08-10 12:49:03+00:00   \n",
       "\n",
       "                                                 pos  \n",
       "0                           PROPN ADP NOUN ADJ PUNCT  \n",
       "1                                         NOUN PROPN  \n",
       "2  NOUN ADJ PUNCT ADV DET ADJ NOUN PUNCT ADV DET ...  \n",
       "3                        PROPN NOUN X VERB ADJ PUNCT  \n",
       "4  ADV VERB ADP NOUN PRON PRON VERB PUNCT DET NOU...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/authors_pos.csv\").drop([\"Unnamed: 0\", \"comment\"], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "        ('svm', LinearSVC(random_state=42, max_iter=10000)),\n",
    "        ('lr_l1', LogisticRegression(random_state=42, penalty=\"l1\", solver=\"liblinear\"),\n",
    "        ('rf'), RandomForestClassifier(random_state=42))]\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42, penalty=\"l2\", solver=\"liblinear\"))\n",
    "\n",
    "clfs = [MultinomialNB(),\n",
    "        LogisticRegression(random_state=42, penalty=\"l1\", solver=\"liblinear\"),\n",
    "        LogisticRegression(random_state=42, penalty=\"l2\", solver=\"liblinear\"),\n",
    "        LinearSVC(random_state=42, max_iter=10000),\n",
    "        SVC(random_state=42),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        stacking\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [CountVectorizer(ngram_range=(1,1), analyzer=\"word\"), \n",
    "                CountVectorizer(ngram_range=(1,3), analyzer=\"word\"), \n",
    "                TfidfVectorizer(ngram_range=(1,1), analyzer=\"word\"), \n",
    "                TfidfVectorizer(ngram_range=(1,3), analyzer=\"word\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ===> MultinomialNB() | TfidfVectorizer()\n",
      "Running ===> MultinomialNB() | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> MultinomialNB() | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> MultinomialNB() | CountVectorizer()\n",
      "Running ===> LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | CountVectorizer()\n",
      "Running ===> LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | TfidfVectorizer()\n",
      "Running ===> LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== MultinomialNB() | CountVectorizer()\n",
      "Running ===> LogisticRegression(random_state=42, solver='liblinear') | CountVectorizer()\n",
      "Finish <=== LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | CountVectorizer()\n",
      "Running ===> LogisticRegression(random_state=42, solver='liblinear') | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== MultinomialNB() | TfidfVectorizer()\n",
      "Running ===> LogisticRegression(random_state=42, solver='liblinear') | TfidfVectorizer()\n",
      "Finish <=== LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | TfidfVectorizer()\n",
      "Running ===> LogisticRegression(random_state=42, solver='liblinear') | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== MultinomialNB() | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> LinearSVC(max_iter=10000, random_state=42) | CountVectorizer()\n",
      "Finish <=== LogisticRegression(random_state=42, solver='liblinear') | CountVectorizer()\n",
      "Running ===> LinearSVC(max_iter=10000, random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== LogisticRegression(random_state=42, solver='liblinear') | TfidfVectorizer()\n",
      "Running ===> LinearSVC(max_iter=10000, random_state=42) | TfidfVectorizer()\n",
      "Finish <=== MultinomialNB() | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> LinearSVC(max_iter=10000, random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> SVC(random_state=42) | CountVectorizer()\n",
      "Finish <=== LogisticRegression(penalty='l1', random_state=42, solver='liblinear') | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> SVC(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== LinearSVC(max_iter=10000, random_state=42) | CountVectorizer()\n",
      "Running ===> SVC(random_state=42) | TfidfVectorizer()\n",
      "Finish <=== LogisticRegression(random_state=42, solver='liblinear') | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> SVC(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== LinearSVC(max_iter=10000, random_state=42) | TfidfVectorizer()\n",
      "Running ===> DecisionTreeClassifier(random_state=42) | CountVectorizer()\n",
      "Finish <=== LogisticRegression(random_state=42, solver='liblinear') | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> DecisionTreeClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== LinearSVC(max_iter=10000, random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> DecisionTreeClassifier(random_state=42) | TfidfVectorizer()\n",
      "Finish <=== SVC(random_state=42) | CountVectorizer()\n",
      "Running ===> DecisionTreeClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== LinearSVC(max_iter=10000, random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> RandomForestClassifier(random_state=42) | CountVectorizer()\n",
      "Finish <=== DecisionTreeClassifier(random_state=42) | CountVectorizer()\n",
      "Running ===> RandomForestClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== SVC(random_state=42) | TfidfVectorizer()\n",
      "Running ===> RandomForestClassifier(random_state=42) | TfidfVectorizer()\n",
      "Finish <=== DecisionTreeClassifier(random_state=42) | TfidfVectorizer()\n",
      "Running ===> RandomForestClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== DecisionTreeClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> AdaBoostClassifier(random_state=42) | CountVectorizer()\n",
      "Finish <=== DecisionTreeClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> AdaBoostClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== AdaBoostClassifier(random_state=42) | CountVectorizer()\n",
      "Running ===> AdaBoostClassifier(random_state=42) | TfidfVectorizer()\n",
      "Finish <=== RandomForestClassifier(random_state=42) | CountVectorizer()\n",
      "Running ===> AdaBoostClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== RandomForestClassifier(random_state=42) | TfidfVectorizer()\n",
      "Running ===> GradientBoostingClassifier(random_state=42) | CountVectorizer()\n",
      "Finish <=== SVC(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> GradientBoostingClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== SVC(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> GradientBoostingClassifier(random_state=42) | TfidfVectorizer()\n",
      "Finish <=== AdaBoostClassifier(random_state=42) | TfidfVectorizer()\n",
      "Running ===> GradientBoostingClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== RandomForestClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | CountVectorizer()\n",
      "Finish <=== RandomForestClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Running ===> StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== AdaBoostClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n",
      "Running ===> StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | TfidfVectorizer()\n",
      "Finish <=== StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | CountVectorizer()\n",
      "Running ===> StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== GradientBoostingClassifier(random_state=42) | CountVectorizer()\n",
      "Finish <=== StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | TfidfVectorizer()\n",
      "Finish <=== AdaBoostClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== GradientBoostingClassifier(random_state=42) | TfidfVectorizer()\n",
      "Finish <=== StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | CountVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear')) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== GradientBoostingClassifier(random_state=42) | TfidfVectorizer(ngram_range=(1, 3))\n",
      "Finish <=== GradientBoostingClassifier(random_state=42) | CountVectorizer(ngram_range=(1, 3))\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def process(clf, vectorizer):\n",
    "    clf_str = clf.__str__()\n",
    "    vect_str = vectorizer.__str__()\n",
    "    print(f\"Running ===> {clf_str} | {vect_str}\")\n",
    "    evaluation = list()\n",
    "    usernames = list(np.unique(data[\"username\"]))\n",
    "\n",
    "    for i in range(len(usernames)):\n",
    "        author1 = usernames.pop()\n",
    "\n",
    "        for author2 in usernames:\n",
    "            X_train, X_test, y_train, y_test = temporal_train_test_split(   \n",
    "                data, author1, author2)\n",
    "\n",
    "            author_clf = AuthorClassifier(clf=clf, vectorizer=vectorizer, scaler=MaxAbsScaler())\n",
    "            author_clf.fit(X_train.iloc[:,0], y_train)\n",
    "            y_pred = author_clf.predict(X_test.iloc[:,0])\n",
    "            evaluation.append(author_clf.evaluate(y_test, y_pred))\n",
    "            metrics = pd.DataFrame(evaluation)[[\"f1_macro\", \"recall_macro\", \"precision_macro\", \"accuracy\", \"auc_score\"]].mean()\n",
    "\n",
    "    print(f\"Finish <=== {clf_str} | {vect_str}\")\n",
    "    return (clf_str, vect_str, metrics)\n",
    "        \n",
    "results = Parallel(n_jobs=8)(delayed(process)(clf, vectorizer) for clf in clfs for vectorizer in vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526834</td>\n",
       "      <td>0.583780</td>\n",
       "      <td>0.626990</td>\n",
       "      <td>0.590880</td>\n",
       "      <td>0.709742</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694003</td>\n",
       "      <td>0.697130</td>\n",
       "      <td>0.708136</td>\n",
       "      <td>0.698818</td>\n",
       "      <td>0.787522</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.645791</td>\n",
       "      <td>0.652819</td>\n",
       "      <td>0.667990</td>\n",
       "      <td>0.654232</td>\n",
       "      <td>0.730966</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.713111</td>\n",
       "      <td>0.715467</td>\n",
       "      <td>0.724098</td>\n",
       "      <td>0.716042</td>\n",
       "      <td>0.800243</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.702575</td>\n",
       "      <td>0.707110</td>\n",
       "      <td>0.716005</td>\n",
       "      <td>0.706065</td>\n",
       "      <td>0.777946</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>LogisticRegression(penalty='l1', random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.736984</td>\n",
       "      <td>0.739660</td>\n",
       "      <td>0.745718</td>\n",
       "      <td>0.738659</td>\n",
       "      <td>0.813783</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>LogisticRegression(penalty='l1', random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.718652</td>\n",
       "      <td>0.719491</td>\n",
       "      <td>0.722492</td>\n",
       "      <td>0.719950</td>\n",
       "      <td>0.783921</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>LogisticRegression(penalty='l1', random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.769256</td>\n",
       "      <td>0.769686</td>\n",
       "      <td>0.770716</td>\n",
       "      <td>0.769584</td>\n",
       "      <td>0.844366</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>LogisticRegression(penalty='l1', random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.660734</td>\n",
       "      <td>0.668247</td>\n",
       "      <td>0.682267</td>\n",
       "      <td>0.667690</td>\n",
       "      <td>0.740828</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.730487</td>\n",
       "      <td>0.732553</td>\n",
       "      <td>0.737098</td>\n",
       "      <td>0.731750</td>\n",
       "      <td>0.807453</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.716351</td>\n",
       "      <td>0.717329</td>\n",
       "      <td>0.721052</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.783489</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.759059</td>\n",
       "      <td>0.759451</td>\n",
       "      <td>0.760766</td>\n",
       "      <td>0.759499</td>\n",
       "      <td>0.836550</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.690328</td>\n",
       "      <td>0.695290</td>\n",
       "      <td>0.706238</td>\n",
       "      <td>0.694239</td>\n",
       "      <td>0.769144</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>LinearSVC(max_iter=10000, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.715424</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.718672</td>\n",
       "      <td>0.716130</td>\n",
       "      <td>0.781061</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>LinearSVC(max_iter=10000, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.717020</td>\n",
       "      <td>0.717991</td>\n",
       "      <td>0.721495</td>\n",
       "      <td>0.718528</td>\n",
       "      <td>0.783577</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>LinearSVC(max_iter=10000, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.730915</td>\n",
       "      <td>0.731289</td>\n",
       "      <td>0.732275</td>\n",
       "      <td>0.731355</td>\n",
       "      <td>0.796237</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>LinearSVC(max_iter=10000, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.706698</td>\n",
       "      <td>0.710792</td>\n",
       "      <td>0.719225</td>\n",
       "      <td>0.709718</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.694274</td>\n",
       "      <td>0.697127</td>\n",
       "      <td>0.702248</td>\n",
       "      <td>0.696396</td>\n",
       "      <td>0.770738</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.742430</td>\n",
       "      <td>0.743115</td>\n",
       "      <td>0.745158</td>\n",
       "      <td>0.743162</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.730197</td>\n",
       "      <td>0.732874</td>\n",
       "      <td>0.743796</td>\n",
       "      <td>0.733516</td>\n",
       "      <td>0.820674</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.681290</td>\n",
       "      <td>0.681600</td>\n",
       "      <td>0.682134</td>\n",
       "      <td>0.681705</td>\n",
       "      <td>0.683128</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.710837</td>\n",
       "      <td>0.711133</td>\n",
       "      <td>0.711770</td>\n",
       "      <td>0.711215</td>\n",
       "      <td>0.714062</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.682172</td>\n",
       "      <td>0.682552</td>\n",
       "      <td>0.683207</td>\n",
       "      <td>0.682642</td>\n",
       "      <td>0.682970</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.710606</td>\n",
       "      <td>0.710937</td>\n",
       "      <td>0.711414</td>\n",
       "      <td>0.710894</td>\n",
       "      <td>0.713032</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.738186</td>\n",
       "      <td>0.738868</td>\n",
       "      <td>0.740857</td>\n",
       "      <td>0.738808</td>\n",
       "      <td>0.808990</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.758691</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.764893</td>\n",
       "      <td>0.760093</td>\n",
       "      <td>0.834961</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.740880</td>\n",
       "      <td>0.741599</td>\n",
       "      <td>0.743308</td>\n",
       "      <td>0.741390</td>\n",
       "      <td>0.811789</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.759905</td>\n",
       "      <td>0.761276</td>\n",
       "      <td>0.765382</td>\n",
       "      <td>0.761031</td>\n",
       "      <td>0.838459</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.733325</td>\n",
       "      <td>0.734321</td>\n",
       "      <td>0.736446</td>\n",
       "      <td>0.734041</td>\n",
       "      <td>0.805475</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.758280</td>\n",
       "      <td>0.759163</td>\n",
       "      <td>0.760909</td>\n",
       "      <td>0.758829</td>\n",
       "      <td>0.830719</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.730306</td>\n",
       "      <td>0.730786</td>\n",
       "      <td>0.732194</td>\n",
       "      <td>0.730859</td>\n",
       "      <td>0.794486</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.751539</td>\n",
       "      <td>0.752035</td>\n",
       "      <td>0.753013</td>\n",
       "      <td>0.751872</td>\n",
       "      <td>0.821198</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.744587</td>\n",
       "      <td>0.745448</td>\n",
       "      <td>0.747418</td>\n",
       "      <td>0.745191</td>\n",
       "      <td>0.821410</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.772278</td>\n",
       "      <td>0.773247</td>\n",
       "      <td>0.775893</td>\n",
       "      <td>0.772886</td>\n",
       "      <td>0.849816</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.740631</td>\n",
       "      <td>0.741150</td>\n",
       "      <td>0.742521</td>\n",
       "      <td>0.741102</td>\n",
       "      <td>0.811398</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.770398</td>\n",
       "      <td>0.771076</td>\n",
       "      <td>0.772884</td>\n",
       "      <td>0.770843</td>\n",
       "      <td>0.847497</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.708195</td>\n",
       "      <td>0.711210</td>\n",
       "      <td>0.716309</td>\n",
       "      <td>0.710243</td>\n",
       "      <td>0.779409</td>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.741460</td>\n",
       "      <td>0.743217</td>\n",
       "      <td>0.746686</td>\n",
       "      <td>0.742487</td>\n",
       "      <td>0.814985</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.718662</td>\n",
       "      <td>0.719401</td>\n",
       "      <td>0.722059</td>\n",
       "      <td>0.719879</td>\n",
       "      <td>0.784083</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.766693</td>\n",
       "      <td>0.767036</td>\n",
       "      <td>0.767981</td>\n",
       "      <td>0.767021</td>\n",
       "      <td>0.839915</td>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_macro  recall_macro  precision_macro  accuracy  auc_score  \\\n",
       "0   0.526834      0.583780         0.626990  0.590880   0.709742   \n",
       "1   0.694003      0.697130         0.708136  0.698818   0.787522   \n",
       "2   0.645791      0.652819         0.667990  0.654232   0.730966   \n",
       "3   0.713111      0.715467         0.724098  0.716042   0.800243   \n",
       "4   0.702575      0.707110         0.716005  0.706065   0.777946   \n",
       "5   0.736984      0.739660         0.745718  0.738659   0.813783   \n",
       "6   0.718652      0.719491         0.722492  0.719950   0.783921   \n",
       "7   0.769256      0.769686         0.770716  0.769584   0.844366   \n",
       "8   0.660734      0.668247         0.682267  0.667690   0.740828   \n",
       "9   0.730487      0.732553         0.737098  0.731750   0.807453   \n",
       "10  0.716351      0.717329         0.721052  0.717914   0.783489   \n",
       "11  0.759059      0.759451         0.760766  0.759499   0.836550   \n",
       "12  0.690328      0.695290         0.706238  0.694239   0.769144   \n",
       "13  0.715424      0.716667         0.718672  0.716130   0.781061   \n",
       "14  0.717020      0.717991         0.721495  0.718528   0.783577   \n",
       "15  0.730915      0.731289         0.732275  0.731355   0.796237   \n",
       "16  0.706698      0.710792         0.719225  0.709718   0.785563   \n",
       "17  0.694274      0.697127         0.702248  0.696396   0.770738   \n",
       "18  0.742430      0.743115         0.745158  0.743162   0.811278   \n",
       "19  0.730197      0.732874         0.743796  0.733516   0.820674   \n",
       "20  0.681290      0.681600         0.682134  0.681705   0.683128   \n",
       "21  0.710837      0.711133         0.711770  0.711215   0.714062   \n",
       "22  0.682172      0.682552         0.683207  0.682642   0.682970   \n",
       "23  0.710606      0.710937         0.711414  0.710894   0.713032   \n",
       "24  0.738186      0.738868         0.740857  0.738808   0.808990   \n",
       "25  0.758691      0.760090         0.764893  0.760093   0.834961   \n",
       "26  0.740880      0.741599         0.743308  0.741390   0.811789   \n",
       "27  0.759905      0.761276         0.765382  0.761031   0.838459   \n",
       "28  0.733325      0.734321         0.736446  0.734041   0.805475   \n",
       "29  0.758280      0.759163         0.760909  0.758829   0.830719   \n",
       "30  0.730306      0.730786         0.732194  0.730859   0.794486   \n",
       "31  0.751539      0.752035         0.753013  0.751872   0.821198   \n",
       "32  0.744587      0.745448         0.747418  0.745191   0.821410   \n",
       "33  0.772278      0.773247         0.775893  0.772886   0.849816   \n",
       "34  0.740631      0.741150         0.742521  0.741102   0.811398   \n",
       "35  0.770398      0.771076         0.772884  0.770843   0.847497   \n",
       "36  0.708195      0.711210         0.716309  0.710243   0.779409   \n",
       "37  0.741460      0.743217         0.746686  0.742487   0.814985   \n",
       "38  0.718662      0.719401         0.722059  0.719879   0.784083   \n",
       "39  0.766693      0.767036         0.767981  0.767021   0.839915   \n",
       "\n",
       "                             vectorizer  \\\n",
       "0                     CountVectorizer()   \n",
       "1   CountVectorizer(ngram_range=(1, 3))   \n",
       "2                     TfidfVectorizer()   \n",
       "3   TfidfVectorizer(ngram_range=(1, 3))   \n",
       "4                     CountVectorizer()   \n",
       "5   CountVectorizer(ngram_range=(1, 3))   \n",
       "6                     TfidfVectorizer()   \n",
       "7   TfidfVectorizer(ngram_range=(1, 3))   \n",
       "8                     CountVectorizer()   \n",
       "9   CountVectorizer(ngram_range=(1, 3))   \n",
       "10                    TfidfVectorizer()   \n",
       "11  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "12                    CountVectorizer()   \n",
       "13  CountVectorizer(ngram_range=(1, 3))   \n",
       "14                    TfidfVectorizer()   \n",
       "15  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "16                    CountVectorizer()   \n",
       "17  CountVectorizer(ngram_range=(1, 3))   \n",
       "18                    TfidfVectorizer()   \n",
       "19  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "20                    CountVectorizer()   \n",
       "21  CountVectorizer(ngram_range=(1, 3))   \n",
       "22                    TfidfVectorizer()   \n",
       "23  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "24                    CountVectorizer()   \n",
       "25  CountVectorizer(ngram_range=(1, 3))   \n",
       "26                    TfidfVectorizer()   \n",
       "27  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "28                    CountVectorizer()   \n",
       "29  CountVectorizer(ngram_range=(1, 3))   \n",
       "30                    TfidfVectorizer()   \n",
       "31  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "32                    CountVectorizer()   \n",
       "33  CountVectorizer(ngram_range=(1, 3))   \n",
       "34                    TfidfVectorizer()   \n",
       "35  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "36                    CountVectorizer()   \n",
       "37  CountVectorizer(ngram_range=(1, 3))   \n",
       "38                    TfidfVectorizer()   \n",
       "39  TfidfVectorizer(ngram_range=(1, 3))   \n",
       "\n",
       "                                           classifier  \n",
       "0                                     MultinomialNB()  \n",
       "1                                     MultinomialNB()  \n",
       "2                                     MultinomialNB()  \n",
       "3                                     MultinomialNB()  \n",
       "4   LogisticRegression(penalty='l1', random_state=...  \n",
       "5   LogisticRegression(penalty='l1', random_state=...  \n",
       "6   LogisticRegression(penalty='l1', random_state=...  \n",
       "7   LogisticRegression(penalty='l1', random_state=...  \n",
       "8   LogisticRegression(random_state=42, solver='li...  \n",
       "9   LogisticRegression(random_state=42, solver='li...  \n",
       "10  LogisticRegression(random_state=42, solver='li...  \n",
       "11  LogisticRegression(random_state=42, solver='li...  \n",
       "12         LinearSVC(max_iter=10000, random_state=42)  \n",
       "13         LinearSVC(max_iter=10000, random_state=42)  \n",
       "14         LinearSVC(max_iter=10000, random_state=42)  \n",
       "15         LinearSVC(max_iter=10000, random_state=42)  \n",
       "16                               SVC(random_state=42)  \n",
       "17                               SVC(random_state=42)  \n",
       "18                               SVC(random_state=42)  \n",
       "19                               SVC(random_state=42)  \n",
       "20            DecisionTreeClassifier(random_state=42)  \n",
       "21            DecisionTreeClassifier(random_state=42)  \n",
       "22            DecisionTreeClassifier(random_state=42)  \n",
       "23            DecisionTreeClassifier(random_state=42)  \n",
       "24            RandomForestClassifier(random_state=42)  \n",
       "25            RandomForestClassifier(random_state=42)  \n",
       "26            RandomForestClassifier(random_state=42)  \n",
       "27            RandomForestClassifier(random_state=42)  \n",
       "28                AdaBoostClassifier(random_state=42)  \n",
       "29                AdaBoostClassifier(random_state=42)  \n",
       "30                AdaBoostClassifier(random_state=42)  \n",
       "31                AdaBoostClassifier(random_state=42)  \n",
       "32        GradientBoostingClassifier(random_state=42)  \n",
       "33        GradientBoostingClassifier(random_state=42)  \n",
       "34        GradientBoostingClassifier(random_state=42)  \n",
       "35        GradientBoostingClassifier(random_state=42)  \n",
       "36  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "37  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "38  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "39  StackingClassifier(estimators=[('svm',\\n      ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([results[i][2] for i in range(len(results))])\n",
    "metrics_df[\"vectorizer\"] = [results[i][1] for i in range(len(results))]\n",
    "metrics_df[\"classifier\"] = [results[i][0] for i in range(len(results))]\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"../../results/pos_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c47aa80a392bf6b860d7beb7b265756c1d97ffcd6d5effdf04ac88dd49d67208"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('reddit-in-portuguese-CNZVnMpw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

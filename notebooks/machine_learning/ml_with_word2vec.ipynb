{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../libs')\n",
    "from utils import temporal_train_test_split\n",
    "from autorship import AuthorClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manada_2</td>\n",
       "      <td>2022-03-09 14:17:46+00:00</td>\n",
       "      <td>-0.432714</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>1.099305</td>\n",
       "      <td>0.864218</td>\n",
       "      <td>0.837875</td>\n",
       "      <td>-3.109633</td>\n",
       "      <td>0.559502</td>\n",
       "      <td>3.881276</td>\n",
       "      <td>...</td>\n",
       "      <td>2.906217</td>\n",
       "      <td>0.421129</td>\n",
       "      <td>1.411148</td>\n",
       "      <td>1.064761</td>\n",
       "      <td>1.959023</td>\n",
       "      <td>1.601933</td>\n",
       "      <td>0.523119</td>\n",
       "      <td>0.897019</td>\n",
       "      <td>-0.426631</td>\n",
       "      <td>0.103120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BluePirate89</td>\n",
       "      <td>2022-03-31 16:00:06+00:00</td>\n",
       "      <td>0.125898</td>\n",
       "      <td>-0.242185</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>0.735328</td>\n",
       "      <td>0.204172</td>\n",
       "      <td>-0.287813</td>\n",
       "      <td>0.222079</td>\n",
       "      <td>0.502998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112329</td>\n",
       "      <td>-0.015934</td>\n",
       "      <td>0.373650</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.104709</td>\n",
       "      <td>0.382138</td>\n",
       "      <td>-0.123530</td>\n",
       "      <td>0.540850</td>\n",
       "      <td>-0.093899</td>\n",
       "      <td>-0.297840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9-Cortes</td>\n",
       "      <td>2021-11-29 02:08:23+00:00</td>\n",
       "      <td>-1.789684</td>\n",
       "      <td>0.469343</td>\n",
       "      <td>0.480798</td>\n",
       "      <td>1.275060</td>\n",
       "      <td>1.201183</td>\n",
       "      <td>-4.118136</td>\n",
       "      <td>0.754351</td>\n",
       "      <td>5.680286</td>\n",
       "      <td>...</td>\n",
       "      <td>2.970081</td>\n",
       "      <td>1.143064</td>\n",
       "      <td>0.718834</td>\n",
       "      <td>0.835258</td>\n",
       "      <td>3.357937</td>\n",
       "      <td>2.351601</td>\n",
       "      <td>1.128088</td>\n",
       "      <td>-0.537648</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>-0.016753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Supermunch2000</td>\n",
       "      <td>2021-12-21 12:01:05+00:00</td>\n",
       "      <td>0.515221</td>\n",
       "      <td>-0.989140</td>\n",
       "      <td>0.209595</td>\n",
       "      <td>3.852181</td>\n",
       "      <td>0.815947</td>\n",
       "      <td>-1.457306</td>\n",
       "      <td>1.570920</td>\n",
       "      <td>3.043237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800782</td>\n",
       "      <td>-0.175123</td>\n",
       "      <td>1.634715</td>\n",
       "      <td>3.569113</td>\n",
       "      <td>1.248902</td>\n",
       "      <td>2.070493</td>\n",
       "      <td>-0.804131</td>\n",
       "      <td>2.869144</td>\n",
       "      <td>-0.717174</td>\n",
       "      <td>-1.667274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheGza1</td>\n",
       "      <td>2021-08-10 12:49:03+00:00</td>\n",
       "      <td>-1.702236</td>\n",
       "      <td>0.606132</td>\n",
       "      <td>0.567707</td>\n",
       "      <td>1.606782</td>\n",
       "      <td>1.322883</td>\n",
       "      <td>-4.053791</td>\n",
       "      <td>0.866824</td>\n",
       "      <td>5.870177</td>\n",
       "      <td>...</td>\n",
       "      <td>3.181649</td>\n",
       "      <td>0.857197</td>\n",
       "      <td>0.913484</td>\n",
       "      <td>0.512868</td>\n",
       "      <td>3.121929</td>\n",
       "      <td>2.340846</td>\n",
       "      <td>1.325590</td>\n",
       "      <td>-0.597204</td>\n",
       "      <td>-0.446730</td>\n",
       "      <td>0.198760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                created_utc         0         1         2  \\\n",
       "0        Manada_2  2022-03-09 14:17:46+00:00 -0.432714  0.032157  1.099305   \n",
       "1    BluePirate89  2022-03-31 16:00:06+00:00  0.125898 -0.242185  0.054639   \n",
       "2        9-Cortes  2021-11-29 02:08:23+00:00 -1.789684  0.469343  0.480798   \n",
       "3  Supermunch2000  2021-12-21 12:01:05+00:00  0.515221 -0.989140  0.209595   \n",
       "4         TheGza1  2021-08-10 12:49:03+00:00 -1.702236  0.606132  0.567707   \n",
       "\n",
       "          3         4         5         6         7  ...        90        91  \\\n",
       "0  0.864218  0.837875 -3.109633  0.559502  3.881276  ...  2.906217  0.421129   \n",
       "1  0.735328  0.204172 -0.287813  0.222079  0.502998  ...  0.112329 -0.015934   \n",
       "2  1.275060  1.201183 -4.118136  0.754351  5.680286  ...  2.970081  1.143064   \n",
       "3  3.852181  0.815947 -1.457306  1.570920  3.043237  ...  0.800782 -0.175123   \n",
       "4  1.606782  1.322883 -4.053791  0.866824  5.870177  ...  3.181649  0.857197   \n",
       "\n",
       "         92        93        94        95        96        97        98  \\\n",
       "0  1.411148  1.064761  1.959023  1.601933  0.523119  0.897019 -0.426631   \n",
       "1  0.373650  0.769785  0.104709  0.382138 -0.123530  0.540850 -0.093899   \n",
       "2  0.718834  0.835258  3.357937  2.351601  1.128088 -0.537648 -0.405631   \n",
       "3  1.634715  3.569113  1.248902  2.070493 -0.804131  2.869144 -0.717174   \n",
       "4  0.913484  0.512868  3.121929  2.340846  1.325590 -0.597204 -0.446730   \n",
       "\n",
       "         99  \n",
       "0  0.103120  \n",
       "1 -0.297840  \n",
       "2 -0.016753  \n",
       "3 -1.667274  \n",
       "4  0.198760  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/authors_word2vec.csv\").drop([\"Unnamed: 0\", \"comment\"], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "        ('svm', LinearSVC(random_state=42, max_iter=10000)),\n",
    "        ('lr_l1', LogisticRegression(random_state=42, penalty=\"l1\", solver=\"liblinear\"),\n",
    "        ('rf'), RandomForestClassifier(random_state=42))]\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42, penalty=\"l2\", solver=\"liblinear\"))\n",
    "\n",
    "clfs = [MultinomialNB(),\n",
    "        LogisticRegression(random_state=42, penalty=\"l1\", solver=\"liblinear\"),\n",
    "        LogisticRegression(random_state=42, penalty=\"l2\", solver=\"liblinear\"),\n",
    "        LinearSVC(random_state=42, max_iter=10000),\n",
    "        SVC(random_state=42),\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        stacking\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ===> MultinomialNB()\n",
      "Running ===> LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "Running ===> LogisticRegression(random_state=42, solver='liblinear')\n",
      "Running ===> DecisionTreeClassifier(random_state=42)\n",
      "Running ===> LinearSVC(max_iter=10000, random_state=42)\n",
      "Running ===> SVC(random_state=42)\n",
      "Finish <=== MultinomialNB()\n",
      "Running ===> RandomForestClassifier(random_state=42)\n",
      "Finish <=== LogisticRegression(random_state=42, solver='liblinear')\n",
      "Running ===> AdaBoostClassifier(random_state=42)\n",
      "Finish <=== DecisionTreeClassifier(random_state=42)\n",
      "Running ===> GradientBoostingClassifier(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/.local/share/virtualenvs/reddit-in-portuguese-Kyc7Ejcc/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish <=== SVC(random_state=42)\n",
      "Running ===> StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/.local/share/virtualenvs/reddit-in-portuguese-Kyc7Ejcc/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish <=== LogisticRegression(penalty='l1', random_state=42, solver='liblinear')\n",
      "Finish <=== LinearSVC(max_iter=10000, random_state=42)\n",
      "Finish <=== RandomForestClassifier(random_state=42)\n",
      "Finish <=== AdaBoostClassifier(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/.local/share/virtualenvs/reddit-in-portuguese-Kyc7Ejcc/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/vinicius/.local/share/virtualenvs/reddit-in-portuguese-Kyc7Ejcc/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish <=== GradientBoostingClassifier(random_state=42)\n",
      "Finish <=== StackingClassifier(estimators=[('svm',\n",
      "                                LinearSVC(max_iter=10000, random_state=42)),\n",
      "                               ('lr_l1',\n",
      "                                LogisticRegression(penalty='l1',\n",
      "                                                   random_state=42,\n",
      "                                                   solver='liblinear'),\n",
      "                                'rf',\n",
      "                                RandomForestClassifier(random_state=42))],\n",
      "                   final_estimator=LogisticRegression(random_state=42,\n",
      "                                                      solver='liblinear'))\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def process(clf):\n",
    "    clf_str = clf.__str__()\n",
    "    print(f\"Running ===> {clf_str}\")\n",
    "    evaluation = list()\n",
    "    clf_list = list()\n",
    "    usernames = list(np.unique(data[\"username\"]))\n",
    "\n",
    "    for i in range(len(usernames)):\n",
    "        author1 = usernames.pop()\n",
    "\n",
    "        for author2 in usernames:\n",
    "            X_train, X_test, y_train, y_test = temporal_train_test_split(   \n",
    "                data, author1, author2)\n",
    "\n",
    "            author_clf = AuthorClassifier(clf=clf, scaler=MinMaxScaler(), embeddings=True)\n",
    "            author_clf.fit(X_train, y_train)\n",
    "            y_pred = author_clf.predict(X_test)\n",
    "            evaluation.append(author_clf.evaluate(y_test, y_pred))\n",
    "            clf_list.append(clf_str)\n",
    "            metrics = pd.DataFrame(evaluation)[[\"f1_macro\", \"recall_macro\", \"precision_macro\", \"accuracy\", \"auc_score\"]].mean()\n",
    "\n",
    "    print(f\"Finish <=== {clf_str}\")\n",
    "    return (clf_str, metrics, evaluation, clf_list)\n",
    "        \n",
    "results = Parallel(n_jobs=6)(delayed(process)(clf) for clf in clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author1</th>\n",
       "      <th>author2</th>\n",
       "      <th>precision_author1</th>\n",
       "      <th>recall_author1</th>\n",
       "      <th>f1_score_author1</th>\n",
       "      <th>precision_author2</th>\n",
       "      <th>recall_author2</th>\n",
       "      <th>f1_score_author2</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9-Cortes</td>\n",
       "      <td>xanax101010</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.5116</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.7374</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6246</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AgnaldoTeExplode</td>\n",
       "      <td>xanax101010</td>\n",
       "      <td>0.5799</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.7098</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.6056</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BeatoSalut</td>\n",
       "      <td>xanax101010</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.4743</td>\n",
       "      <td>0.3416</td>\n",
       "      <td>0.3971</td>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.4830</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BluePirate89</td>\n",
       "      <td>xanax101010</td>\n",
       "      <td>0.6221</td>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.6346</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>0.5722</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.5727</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CariocaSatanico</td>\n",
       "      <td>xanax101010</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.7468</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.7486</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6321</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>AgnaldoTeExplode</td>\n",
       "      <td>BluePirate89</td>\n",
       "      <td>0.7992</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.8634</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>BeatoSalut</td>\n",
       "      <td>BluePirate89</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>0.6976</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.6926</td>\n",
       "      <td>0.6953</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.6952</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.6952</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.7573</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>9-Cortes</td>\n",
       "      <td>BeatoSalut</td>\n",
       "      <td>0.7614</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.7224</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>0.7970</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>AgnaldoTeExplode</td>\n",
       "      <td>BeatoSalut</td>\n",
       "      <td>0.7623</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.8011</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>9-Cortes</td>\n",
       "      <td>AgnaldoTeExplode</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.6734</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.6948</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6941</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.7669</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author1           author2  precision_author1  recall_author1  \\\n",
       "0             9-Cortes       xanax101010             0.6036          0.9478   \n",
       "1     AgnaldoTeExplode       xanax101010             0.5799          0.9145   \n",
       "2           BeatoSalut       xanax101010             0.4888          0.6245   \n",
       "3         BluePirate89       xanax101010             0.6221          0.4332   \n",
       "4      CariocaSatanico       xanax101010             0.6071          0.9558   \n",
       "...                ...               ...                ...             ...   \n",
       "1045  AgnaldoTeExplode      BluePirate89             0.7992          0.8675   \n",
       "1046        BeatoSalut      BluePirate89             0.6892          0.7061   \n",
       "1047          9-Cortes        BeatoSalut             0.7614          0.8715   \n",
       "1048  AgnaldoTeExplode        BeatoSalut             0.7623          0.8632   \n",
       "1049          9-Cortes  AgnaldoTeExplode             0.7149          0.6747   \n",
       "\n",
       "      f1_score_author1  precision_author2  recall_author2  f1_score_author2  \\\n",
       "0               0.7375             0.8713          0.3621            0.5116   \n",
       "1               0.7098             0.8148          0.3621            0.5014   \n",
       "2               0.5484             0.4743          0.3416            0.3971   \n",
       "3               0.5107             0.5597          0.7325            0.6346   \n",
       "4               0.7426             0.8900          0.3663            0.5190   \n",
       "...                ...                ...             ...               ...   \n",
       "1045            0.8320             0.8634          0.7935            0.8270   \n",
       "1046            0.6976             0.7012          0.6842            0.6926   \n",
       "1047            0.8127             0.8469          0.7224            0.7797   \n",
       "1048            0.8096             0.8505          0.7429            0.7930   \n",
       "1049            0.6942             0.6734          0.7137            0.6929   \n",
       "\n",
       "      precision_weighted  precision_micro  precision_macro  recall_weighted  \\\n",
       "0                 0.7358           0.6585           0.7374           0.6585   \n",
       "1                 0.6996           0.6331           0.6974           0.6331   \n",
       "2                 0.4816           0.4836           0.4816           0.4836   \n",
       "3                 0.5912           0.5816           0.5909           0.5816   \n",
       "4                 0.7468           0.6646           0.7486           0.6646   \n",
       "...                  ...              ...              ...              ...   \n",
       "1045              0.8322           0.8295           0.8313           0.8295   \n",
       "1046              0.6953           0.6951           0.6952           0.6951   \n",
       "1047              0.8038           0.7976           0.8041           0.7976   \n",
       "1048              0.8074           0.8017           0.8064           0.8017   \n",
       "1049              0.6948           0.6936           0.6941           0.6936   \n",
       "\n",
       "      recall_micro  recall_macro  f1_weighted  f1_micro  f1_macro  auc_score  \\\n",
       "0           0.6585        0.6550       0.6259    0.6585    0.6246     0.7651   \n",
       "1           0.6331        0.6383       0.6036    0.6331    0.6056     0.6978   \n",
       "2           0.4836        0.4830       0.4731    0.4836    0.4728     0.5374   \n",
       "3           0.5816        0.5829       0.5722    0.5816    0.5727     0.6053   \n",
       "4           0.6646        0.6610       0.6321    0.6646    0.6308     0.7458   \n",
       "...            ...           ...          ...       ...       ...        ...   \n",
       "1045        0.8295        0.8305       0.8294    0.8295    0.8295     0.9012   \n",
       "1046        0.6951        0.6952       0.6951    0.6951    0.6951     0.7573   \n",
       "1047        0.7976        0.7970       0.7964    0.7976    0.7962     0.8492   \n",
       "1048        0.8017        0.8031       0.8011    0.8017    0.8013     0.8636   \n",
       "1049        0.6936        0.6942       0.6936    0.6936    0.6936     0.7669   \n",
       "\n",
       "      accuracy                                                clf  \n",
       "0       0.6585                                    MultinomialNB()  \n",
       "1       0.6331                                    MultinomialNB()  \n",
       "2       0.4836                                    MultinomialNB()  \n",
       "3       0.5816                                    MultinomialNB()  \n",
       "4       0.6646                                    MultinomialNB()  \n",
       "...        ...                                                ...  \n",
       "1045    0.8295  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "1046    0.6951  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "1047    0.7976  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "1048    0.8017  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "1049    0.6936  StackingClassifier(estimators=[('svm',\\n      ...  \n",
       "\n",
       "[1050 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "scores = [results[i][2] for i in range(10)]\n",
    "clfs_list = [results[i][3] for i in range(10)]\n",
    "\n",
    "clfs_list = list(itertools.chain(*clfs_list))\n",
    "scores = list(itertools.chain(*scores))\n",
    "\n",
    "metrics_full = pd.concat([pd.DataFrame(scores), pd.DataFrame(clfs_list, columns=[\"clf\"])], axis=1)\n",
    "metrics_full.to_csv(\"../../results/word2vec_results_full.csv\")\n",
    "metrics_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.630535</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.690520</td>\n",
       "      <td>0.650862</td>\n",
       "      <td>0.710926</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750673</td>\n",
       "      <td>0.752473</td>\n",
       "      <td>0.759603</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.825631</td>\n",
       "      <td>LogisticRegression(penalty='l1', random_state=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.745508</td>\n",
       "      <td>0.747753</td>\n",
       "      <td>0.756851</td>\n",
       "      <td>0.748021</td>\n",
       "      <td>0.822596</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.768187</td>\n",
       "      <td>0.769520</td>\n",
       "      <td>0.775856</td>\n",
       "      <td>0.769770</td>\n",
       "      <td>0.843301</td>\n",
       "      <td>LinearSVC(max_iter=10000, random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.741613</td>\n",
       "      <td>0.745708</td>\n",
       "      <td>0.759746</td>\n",
       "      <td>0.745841</td>\n",
       "      <td>0.836346</td>\n",
       "      <td>SVC(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.696137</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.696498</td>\n",
       "      <td>0.696340</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.773769</td>\n",
       "      <td>0.774320</td>\n",
       "      <td>0.775982</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.848810</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.755216</td>\n",
       "      <td>0.755476</td>\n",
       "      <td>0.756490</td>\n",
       "      <td>0.755632</td>\n",
       "      <td>0.826072</td>\n",
       "      <td>AdaBoostClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.772878</td>\n",
       "      <td>0.773221</td>\n",
       "      <td>0.774362</td>\n",
       "      <td>0.773246</td>\n",
       "      <td>0.848967</td>\n",
       "      <td>GradientBoostingClassifier(random_state=42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.770671</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.775839</td>\n",
       "      <td>0.771796</td>\n",
       "      <td>0.842546</td>\n",
       "      <td>StackingClassifier(estimators=[('svm',\\n      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_macro  recall_macro  precision_macro  accuracy  auc_score  \\\n",
       "0  0.630535      0.650665         0.690520  0.650862   0.710926   \n",
       "1  0.750673      0.752473         0.759603  0.752688   0.825631   \n",
       "2  0.745508      0.747753         0.756851  0.748021   0.822596   \n",
       "3  0.768187      0.769520         0.775856  0.769770   0.843301   \n",
       "4  0.741613      0.745708         0.759746  0.745841   0.836346   \n",
       "5  0.696137      0.696350         0.696900  0.696498   0.696340   \n",
       "6  0.773769      0.774320         0.775982  0.774233   0.848810   \n",
       "7  0.755216      0.755476         0.756490  0.755632   0.826072   \n",
       "8  0.772878      0.773221         0.774362  0.773246   0.848967   \n",
       "9  0.770671      0.771605         0.775839  0.771796   0.842546   \n",
       "\n",
       "                                          classifier  \n",
       "0                                    MultinomialNB()  \n",
       "1  LogisticRegression(penalty='l1', random_state=...  \n",
       "2  LogisticRegression(random_state=42, solver='li...  \n",
       "3         LinearSVC(max_iter=10000, random_state=42)  \n",
       "4                               SVC(random_state=42)  \n",
       "5            DecisionTreeClassifier(random_state=42)  \n",
       "6            RandomForestClassifier(random_state=42)  \n",
       "7                AdaBoostClassifier(random_state=42)  \n",
       "8        GradientBoostingClassifier(random_state=42)  \n",
       "9  StackingClassifier(estimators=[('svm',\\n      ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame([results[i][1] for i in range(len(results))])\n",
    "metrics_df[\"classifier\"] = [results[i][0] for i in range(len(results))]\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"../../results/word2vec_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2961734913207ee881f462d4bc826f1f53aa8b6216ab04f585499525ca3800dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('reddit-in-portuguese-Kyc7Ejcc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

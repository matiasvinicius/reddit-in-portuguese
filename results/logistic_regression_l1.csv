,f1_macro,recall_macro,precision_macro,accuracy,auc_score,vectorizer
0,0.8463514285714285,0.8477961904761906,0.8543714285714286,0.8471266666666667,0.9214447619047619,CountVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f5d206ccd00>>)
1,0.849517142857143,0.8510028571428572,0.8577990476190476,0.8503104761904762,0.9249209523809523,"CountVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f4aac31fd00>>)"
2,0.8325076190476192,0.8336142857142859,0.8382409523809522,0.8330447619047618,0.9111333333333334,"CountVectorizer(analyzer='char', ngram_range=(1, 5))"
3,0.786555238095238,0.7887514285714285,0.796967619047619,0.7880400000000001,0.8728447619047619,"CountVectorizer(analyzer='char', ngram_range=(4, 5))"
4,0.8026361904761904,0.8043257142857143,0.8112209523809524,0.8037047619047618,0.8893561904761905,"CountVectorizer(analyzer='char', ngram_range=(3, 8))"
5,0.8573438095238095,0.8578019047619048,0.8602180952380952,0.8576276190476191,0.9285733333333334,TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7efd8df39d00>>)
6,0.8536171428571429,0.8540352380952381,0.8579057142857143,0.8542085714285714,0.929902857142857,"TfidfVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7efd8df39dc0>>)"
7,0.8615657142857143,0.8617342857142856,0.8623885714285715,0.8616914285714286,0.9295561904761904,"TfidfVectorizer(analyzer='char', ngram_range=(1, 5))"
8,0.8055523809523809,0.8061580952380953,0.8078638095238095,0.8059219047619046,0.8859600000000001,"TfidfVectorizer(analyzer='char', ngram_range=(4, 5))"
9,0.8172238095238096,0.8174219047619047,0.8185276190476193,0.8175076190476189,0.8975276190476191,"TfidfVectorizer(analyzer='char', ngram_range=(3, 8))"

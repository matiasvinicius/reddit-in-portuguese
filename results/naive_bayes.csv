,f1_macro,recall_macro,precision_macro,accuracy,auc_score,vectorizer
0,0.8030714285714287,0.8053190476190477,0.8226438095238096,0.8063904761904761,0.9049333333333334,CountVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fed7058ed00>>)
1,0.8165961904761906,0.8188685714285714,0.8378619047619049,0.820152380952381,0.9215961904761905,"CountVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fde886a4d00>>)"
2,0.7840514285714284,0.7894190476190477,0.8174142857142858,0.7904790476190475,0.8906085714285713,"CountVectorizer(analyzer='char', ngram_range=(1, 5))"
3,0.7774552380952381,0.7829876190476193,0.8111247619047619,0.7841171428571428,0.887507619047619,"CountVectorizer(analyzer='char', ngram_range=(4, 5))"
4,0.7863028571428572,0.791392380952381,0.8203809523809524,0.792875238095238,0.8844961904761905,"CountVectorizer(analyzer='char', ngram_range=(3, 8))"
5,0.7967190476190477,0.7995657142857142,0.8192790476190477,0.8006142857142857,0.9022809523809523,TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f8a7e9f3d00>>)
6,0.8073095238095239,0.8097571428571427,0.828970476190476,0.8109590476190476,0.9145828571428571,"TfidfVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f8a6adcfee0>>)"
7,0.7668009523809522,0.7734790476190476,0.8049276190476189,0.7745590476190476,0.8820819047619047,"TfidfVectorizer(analyzer='char', ngram_range=(1, 5))"
8,0.7636780952380953,0.7704095238095238,0.802375238095238,0.7716428571428572,0.8832247619047618,"TfidfVectorizer(analyzer='char', ngram_range=(4, 5))"
9,0.7728333333333334,0.7785352380952381,0.8085466666666665,0.780002857142857,0.8710219047619047,"TfidfVectorizer(analyzer='char', ngram_range=(3, 8))"

,f1_macro,recall_macro,precision_macro,accuracy,auc_score,vectorizer
0,0.847452380952381,0.8483723809523811,0.8512819047619048,0.8478619047619047,0.917827619047619,CountVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f06472b3c10>>)
1,0.8493904761904761,0.850167619047619,0.8533190476190475,0.8498409523809524,0.9191542857142856,"CountVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f24fa339c70>>)"
2,0.8517438095238095,0.85226,0.8533133333333333,0.851932380952381,0.9220666666666667,"CountVectorizer(analyzer='char', ngram_range=(1, 5))"
3,0.7710466666666667,0.7738876190476189,0.7817733333333332,0.7732076190476191,0.8517390476190475,"CountVectorizer(analyzer='char', ngram_range=(4, 5))"
4,0.7918057142857143,0.7932009523809523,0.7968857142857143,0.7926714285714286,0.8744514285714285,"CountVectorizer(analyzer='char', ngram_range=(3, 8))"
5,0.8383904761904762,0.8389609523809525,0.8410457142857143,0.8387333333333334,0.9075800000000002,TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7efc6f30ac70>>)
6,0.8334142857142859,0.8343609523809524,0.8376761904761905,0.8339761904761904,0.9033980952380952,"TfidfVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f06472b3c40>>)"
7,0.8403304761904761,0.8405866666666667,0.8413228571428572,0.8405285714285714,0.9128457142857144,"TfidfVectorizer(analyzer='char', ngram_range=(1, 5))"
8,0.7653361904761906,0.7672219047619048,0.7723019047619047,0.7670257142857143,0.8429409523809523,"TfidfVectorizer(analyzer='char', ngram_range=(4, 5))"
9,0.7808742857142857,0.7815190476190477,0.7837571428571428,0.7815228571428572,0.8608390476190477,"TfidfVectorizer(analyzer='char', ngram_range=(3, 8))"

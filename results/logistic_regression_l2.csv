,f1_macro,recall_macro,precision_macro,accuracy,auc_score,vectorizer
0,0.8334314285714285,0.8350066666666667,0.8411180952380951,0.8341761904761904,0.9200600000000002,CountVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f5110515cd0>>)
1,0.8061371428571429,0.8112209523809524,0.8330628571428571,0.8096552380952381,0.9226819047619048,"CountVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fefe58fbcd0>>)"
2,0.8392600000000001,0.8404704761904761,0.8444409523809523,0.8397361904761904,0.9203723809523809,"CountVectorizer(analyzer='char', ngram_range=(1, 5))"
3,0.8223685714285716,0.8241038095238096,0.8298352380952382,0.8232104761904762,0.9071704761904762,"CountVectorizer(analyzer='char', ngram_range=(4, 5))"
4,0.8197742857142858,0.8221504761904762,0.8306533333333332,0.8210561904761904,0.9100685714285713,"CountVectorizer(analyzer='char', ngram_range=(3, 8))"
5,0.8721123809523811,0.8723228571428571,0.8731161904761905,0.8722542857142856,0.9410171428571428,TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f4e9655dcd0>>)
6,0.8521714285714285,0.8527666666666668,0.8586190476190476,0.853072380952381,0.9351133333333332,"TfidfVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f50fc733a00>>)"
7,0.8578495238095238,0.8579980952380952,0.8588942857142856,0.8580371428571429,0.9334428571428571,"TfidfVectorizer(analyzer='char', ngram_range=(1, 5))"
8,0.8379219047619046,0.8382533333333334,0.8393085714285714,0.838135238095238,0.9168895238095237,"TfidfVectorizer(analyzer='char', ngram_range=(4, 5))"
9,0.8402542857142856,0.8405333333333332,0.8422742857142858,0.8405780952380953,0.9194628571428571,"TfidfVectorizer(analyzer='char', ngram_range=(3, 8))"

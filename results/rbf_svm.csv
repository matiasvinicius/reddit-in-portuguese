,f1_macro,recall_macro,precision_macro,accuracy,auc_score,vectorizer
0,0.7594085714285714,0.7655019047619048,0.7857209523809525,0.7639857142857144,0.8632885714285715,CountVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fe433ec9c70>>)
1,0.5919838095238096,0.6465590476190476,0.757004761904762,0.642910476190476,0.8490409523809523,"CountVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fd6391c7cd0>>)"
2,0.746404761904762,0.7525733333333332,0.7712142857142857,0.7510428571428571,0.8444447619047618,"CountVectorizer(analyzer='char', ngram_range=(1, 5))"
3,0.7215819047619048,0.7303095238095237,0.7535266666666666,0.7285952380952382,0.8210038095238095,"CountVectorizer(analyzer='char', ngram_range=(4, 5))"
4,0.6708695238095238,0.6926209523809523,0.7416609523809523,0.6899609523809523,0.8137590476190476,"CountVectorizer(analyzer='char', ngram_range=(3, 8))"
5,0.7696542857142855,0.7744619047619049,0.8013714285714285,0.7765485714285714,0.8788028571428572,TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fd32948ecd0>>)
6,0.685744761904762,0.701624761904762,0.7495485714285713,0.7046314285714286,0.8173561904761903,"TfidfVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fe433ec9c10>>)"
7,0.5870971428571429,0.6365590476190477,0.7372457142857144,0.6408485714285714,0.7842704761904762,"TfidfVectorizer(analyzer='char', ngram_range=(1, 5))"
8,0.5918761904761904,0.635435238095238,0.718572380952381,0.6399885714285714,0.7857790476190476,"TfidfVectorizer(analyzer='char', ngram_range=(4, 5))"
9,0.5406114285714285,0.6006533333333334,0.6951542857142856,0.6057114285714286,0.7660342857142857,"TfidfVectorizer(analyzer='char', ngram_range=(3, 8))"

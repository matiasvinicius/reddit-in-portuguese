,f1_macro,recall_macro,precision_macro,accuracy,auc_score,vectorizer
0,0.8157838095238096,0.817387619047619,0.8225247619047619,0.8165295238095238,0.9013809523809524,CountVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f11ca9e7c70>>)
1,0.7778180952380951,0.7854457142857142,0.8137552380952381,0.7835504761904762,0.9055504761904762,"CountVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f84fb211c70>>)"
2,0.8078171428571428,0.8095095238095238,0.8150914285714287,0.80872,0.8961971428571429,"CountVectorizer(analyzer='char', ngram_range=(1, 5))"
3,0.7855342857142859,0.7885304761904761,0.7978790476190476,0.7873419047619047,0.879297142857143,"CountVectorizer(analyzer='char', ngram_range=(4, 5))"
4,0.7697838095238096,0.774987619047619,0.7916971428571429,0.7737161904761904,0.8762390476190477,"CountVectorizer(analyzer='char', ngram_range=(3, 8))"
5,0.8669457142857142,0.8672285714285716,0.8678104761904762,0.8670638095238096,0.9360609523809524,TfidfVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fb7190c3c70>>)
6,0.8526533333333333,0.8532980952380954,0.8583057142857142,0.8534219047619048,0.9315133333333334,"TfidfVectorizer(ngram_range=(1, 3),
                tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7fb7190c3e20>>)"
7,0.8534533333333335,0.8537323809523809,0.8542076190476189,0.8535561904761905,0.927544761904762,"TfidfVectorizer(analyzer='char', ngram_range=(1, 5))"
8,0.8249123809523808,0.825852380952381,0.828424761904762,0.825375238095238,0.9050285714285713,"TfidfVectorizer(analyzer='char', ngram_range=(4, 5))"
9,0.8259180952380955,0.8262552380952383,0.8271647619047618,0.826104761904762,0.9040057142857142,"TfidfVectorizer(analyzer='char', ngram_range=(3, 8))"
